\documentclass[times, utf8, diplomski, numeric]{fer}
\usepackage{booktabs}
\usepackage{url}
\usepackage{amsmath}
\usepackage{float}
\usepackage[]{algorithmic}
\usepackage[]{algorithm}
\usepackage{diagbox}
\usepackage{pdfpages}
\usepackage{multirow}
\usepackage{hhline}

\renewcommand{\algorithmicfor}{\textbf{Za}}
\renewcommand{\algorithmicendfor}{\textbf{Kraj}}
\renewcommand{\algorithmicdo}{\textbf{Ponavljaj}}
\renewcommand{\algorithmicwhile}{\textbf{Sve dok}}
\renewcommand{\algorithmicendwhile}{\textbf{Kraj}}

\makeatletter
\renewcommand{\ALG@name}{Algoritam}
\makeatother

\allowdisplaybreaks

\begin{document}

\nocite{*}

% TODO: Navedite broj rada.
\thesisnumber{1548}

% TODO: Navedite naslov rada.
\title{Detekcija sigurnosnih atributa prometnica u snimkama}

% TODO: Navedite vaše ime i prezime.
\author{Ivan Relić}

\maketitle

% Ispis stranice s napomenom o umetanju izvornika rada. Uklonite naredbu \izvornik ako želite izbaciti tu stranicu.
\includepdf[pages=-,pagecommand={},width=\paperwidth]{izvornik.pdf}

% Dodavanje zahvale ili prazne stranice. Ako ne želite dodati zahvalu, naredbu ostavite radi prazne stranice.
\zahvala{Zahvaljujem mentoru, izv. prof. dr. sc. Siniši Šegviću, na svim savjetima i pruženoj pomoći tijekom studiranja i tijekom izrade ovog diplomskog rada.

Zahvaljujem svojim roditeljima i sestri na pruženoj potpori tijekom studiranja.

Zahvaljujem svim svojim prijateljima koji su obaveze na fakultetu učinili lakšima, zabavnijima i koji su godine studiranja pretvorili u najljepše godine života.}

\tableofcontents

\chapter{Uvod}
Računalni vid vrlo je značajno područje umjetne inteligencije koje se bavi razumijevanjem slike, odnosno scene na slici. 
Vrlo popularna područja računalnog vida danas su klasifikacija (određivanje pripadnosti scene slike predefiniranom skupu klasa, jednoj ili više njih), semantička segmentacija (podjela slike u dijelove i dodjeljivanje klase svakom od tih dijelova), stereoskopska rekonstrukcija (određivanje 3D geometrije scene iz slika dobivenih parom kamera) te mnoga druga.
Važnost percepcije i razumijevanja okoline dovela je do toga da je računalni vid vrlo popularno područje umjetne inteligencije koje je u stalnom razvoju zbog svojih mnogih primjena.

Duboko učenje donijelo je veliku revoluciju na mnogim područjima umjetne inteligencije, pa tako i na području računalnog vida. 
Duboki modeli pomaknuli su granice najbolje ostvarenih rezultata na mnogim problemima. 
Primjerice,  na problemu klasifikacije slika iz skupa podataka ImageNet \citep{dataset:imagenet} u jednu od tisuću mogućih klasa, najmanja pogreška ostvarena dubokim modelom manja je od pogreške koju na tom skupu podataka ostvaruju ljudi \citep{article:delving_deep_into_rectifiers}. 
Upravo zbog vrlo dobrih rezultata koje duboki modeli ostvaruju, sve više zadataka u kojima ljudi lako griješe i koji su mentalno naporni povjeravaju se na obavljanje računalima.

Dobri rezultati dubokih modela na području računalnog vida svakako otvaraju mnoge primjene računala u praktičnim problemima. 
Jedan takav problem, kojim se ovaj rad bavi, jest inspekcija kvaliteta cesta. 
Organizacija iRAP \engl{International Road Assessment Programe} ima za cilj upravo inspekciju kvaliteta ceste pridruživanjem različitih sigurnosnih atributa segmentima prometnica.
Zadatak se obavlja tako da se na temelju video snimaka prometnica uz geolokacije, pridružene videosnimkama, određuje prisutnost sigurnosnog atributa na tom dijelu prometnice.
Na temelju prisutnih atributa moguće je procijeniti sigurnost promatranog dijela prometnice, što je vrlo korisno.

Trenutno, pridruživanje atributa segmentima prometnica obavljaju ljudi. 
Zadatak je vrlo naporan i skup te su moguće različite greške -- greške uzrokovane subjektivnošću, greške uzrokovane radom različitih osoba na zadatku pridruživanja zbog čega se može pojaviti nekonzistentnost, greške uzrokovane umorom te mnoge druge.
Prednost korištenja dubokog modela za taj zadatak je njegova veća brzina, manja cijena i objektivnost u procjeni u odnosu na čovjeka.

Ovaj rad kroz nekoliko faza opisuje implementaciju dubokog modela koji je sposoban detektirati prisutnost sigurnosnog atributa u video snimci.
Prvi dio rada opisuje korišteni skup podataka -- postupak njegovog prikupljanja te korištenje za učenje dubokog modela.
Drugi dio rada opisuje korištene metode i modele koji na temelju učenja na skupu podataka ostvaruju željenu funkciju koju možemo primijeniti na konkretan problem.
Završni dio rada opisuje provedene eksperimente i dobivene rezultate prilikom korištenja dubokog modela za problem detekcije sigurnosnih atributa u snimkama.


\chapter{Skupovi podataka i njihovo korištenje} \label{chapter:skupovi_podataka}
 
Prepoznavanje prisutnosti sigurnosnih atributa možemo okarakterizirati kao binarnu klasifikaciju čiji konačni izlaz nam govori je li atribut prisutan u sceni ili nije.
Standard organizacije iRAP propisuje 78 sigurnosnih atributa \citep{man:ftts_irap_attributes} koje je moguće pridružiti segmentima prometnica.
Neki od njih su: tip križanja, ograničenje brzine, udaljenost i tip objekata pored ceste i broj prometnih traka.
Pojedine atribute moguće je detektirati u statičnim slikama, dok je neke moguće detektirati samo iz videosnimke -- primjerice, da bismo odredili ograničenje brzine nekog segmenta prometnice, potrebna nam je videosnimka cijelog tog segmenta.

Modeli dubokog učenja danas uspješno rješavaju probleme klasifikacije. Rješavanje takvog problema temelji se na odabiru prikladnog modela uz dovoljan broj označenih podataka. 
Ključna stvar prilikom rješavanja problema klasifikacije jest izvlačenje znanja iz označenih podataka koje model koristi. Takav postupak nazivamo nadziranim učenjem \citep{book:deeplearningbook}. 
Učenje modela svodi se na korekciju slobodnih parametara modela koji ostvaruju željenu funkciju preslikavanja.

Skup podataka možemo podijeliti na 3 podskupa koji imaju različite uloge:
\begin{itemize}
 \item podskup za učenje -- podskup koji se koristi za korekciju slobodnih parametara modela
 \item podskup za validaciju -- podskup koji se koristi za korekciju hiperparametara, odnosno za provjeru sposobnosti generalizacije modela
 \item podskup za testiranje -- podskup koji se koristi za konačno ispitivanje performanse naučenog modela
\end{itemize}


\section{Videosnimke projekta FTTS iRAP}

Kao osnova za kreiranje skupova podataka, korištena je stranica sustava FTTS iRAP \citep{url:ftts_irap}. 
Stranica nudi sučelje u kojem je moguće pregledavati, uređivati i prikupljati sigurnosne atribute prisutne na segmentima prometnica.
Uz same atribute dodijeljene segmentima prometnica, dostupne su i georeferencirane videosnimke -- moguć je pregled videosnimke koja geolokacijom odgovara segmentu.
Videosnimke snimljene su iz automobila koji se kretao po engleskim autocestama te ih je moguće, uz pripadajuće informacije o njihovim geolokacijama, slobodno preuzeti sa stranice \citep{url:ftts_irap}.

Sustav opisan u radu koristi georeferencirane videosnimke s navedene stranice za učenje. Konkretno, kako je riječ o binarnoj klasifikaciji, potrebni su nam označeni podaci. 
Atribut koji sustav prepoznaje jest pripajanje \engl{merge lane} (tip križanja). Kako je riječ o videosnimkama s engleskih cesta, pripajanja koja se prepoznaju bit će s lijeve strane.
Definicija atributa ``pripajanje trakova'' prema pravilima organizacije \citep{man:ftts_irap_coding_manual} jest sljedeća: promet koji prilazi sa strane pripaja se preko linije za pripajanje na cestu kojoj se atribut dodjeljuje.

\begin{figure}[H]
\centering
\includegraphics[scale=0.75]{images/merge_lane.png}
\caption{Simbolički prikaz pripajanja (slika preuzeta i prerađena iz \citep{man:ftts_irap_coding_manual})}
\label{img:merge_lane_symbolic}
\end{figure}

\noindent Slika \ref{img:merge_lane_symbolic} simbolički prikazuje što se konkretno smatra pripajanjem prilikom pridruživanja sigurnosnog atributa pripajanja.
Prilikom označavanja, eksperti za označavanje kao pripajanje označavaju onaj dio prometnice u kojem se automobil iz traka prometnice koja se pripaja mora prebaciti u trak prometnice kojoj se pripaja.
Kao pripajanje se promatra upravo taj dio prometnice, jer predstavlja opasnost zbog toga što vozač prilikom ubacivanja mora promijeniti trak kojim prometuje.

Iz georeferenciranih video snimaka kreirana su dva tipa skupova podataka:
\begin{itemize}
 \item skup podataka s diskriminativnim oznakama (oznake atributa nisu konzistentne s pravilima koja propisuje organizacija iRAP)
 \item skup podataka s oznakama iz sustava FTTS iRAP (oznake atributa su konzistentne s pravilima koja propisuje organizacija iRAP)
\end{itemize}
U nastavku je opisan način kreiranja i uporaba pojedinih tipova skupova podataka.

\section{Skup podataka s diskriminativnim oznakama}
Početna ideja bila je, neovisno o pridruženim atributima pripajanja sa stranice \citep{url:ftts_irap}, označiti pripajanja diskriminativnim oznakama. 

Dubokim modelima je, kao i ljudima, lakše izlučiti znanje iz podataka ukoliko u njima postoje diskriminativne značajke koje mogu odrediti pripadnost određenoj klasi.
Dodjeljivanje oznaka prisutnosti atributa pripajanja prometnoj sceni iz tog se razloga vodilo tom mišlju -- scene na kojima su prisutne karakteristične, diskriminativne značajke koje bi mogle odrediti prisutnost atributa pripajanja označene su kao pozitivne, odnosno scene na kojima je atribut prisutan, dok su ostale označene kao negativne, odnosno scene na kojima atribut nije prisutan.

\begin{figure}[H]
\centering
\includegraphics[scale=0.15]{images/hand_labeled_positive.png}
\caption{Prikaz scene na kojoj je prisutna diskriminativna značajka atributa pripajanja (slika preuzeta s \citep{url:ftts_irap})}
\label{img:hand_labeled_positive}
\end{figure}

\noindent Slika \ref{img:hand_labeled_positive} prikazuje pozitivnu sliku s diskriminativnom oznakom. 
Na slici su vidljive karakteristične bijele trake u uzorku koji bi potencijalno mogao biti diskriminativan prilikom donošenja odluke modela o prisutnosti atributa pripajanja.

\begin{figure}[H]
\centering
\includegraphics[scale=0.15]{images/hand_labeled_negative.png}
\caption{Prikaz scene na kojoj diskriminativna značajka atributa pripajanja nije prisutna (slika preuzeta s \citep{url:ftts_irap})}
\label{img:hand_labeled_negative}
\end{figure}

\noindent Slika \ref{img:hand_labeled_negative} prikazuje negativnu sliku s diskriminativnom oznakom.
Vidljiv je izostanak karakterističnih bijelih traka na cijeloj sceni.

Skup podataka s diskriminativnim oznakama dobiven je obradom 7 video snimaka preuzetih sa stranice \citep{url:ftts_irap}. 
Ukupan broj dobivenih označenih slika s raspodjelom u podskupove je sljedeći:
\begin{itemize}
 \item podskup za učenje -- 1796 slika, od toga 898 pozitivnih
 \item podskup za validaciju -- 626 slika, od toga 313 pozitivnih
 \item podskup za testiranje -- 594 slike, od toga 297 pozitivnih
\end{itemize}

\noindent Skup je kreiran na način da se iz svake videosnimke uzorkuju pozitivni primjeri (primjeri na kojima je prisutna diskriminativna značajka atributa pripajanja) te se zatim uzorkuje isti broj negativnih primjera na kojima diskriminativna značajka karakterističnog bijelog uzorka nije prisutna.

\section{Skup podataka s oznakama iz sustava FTTS iRAP}
U skupu podataka s diskriminativnim oznakama, pozitivne i negativne oznake određene su na temelju prisutnosti diskriminativnog uzorka u sceni. 
Takav način označavanja nije konzistentan s načinom označavanja kakav provode eksperti za označavanje u sustavu FTTS iRAP na stranici \citep{url:ftts_irap}.
Glavni cilj rada jest razviti sustav koji bi mogao automatski određivati prisutnost sigurnosnog atributa na prometnoj sceni. 
Za učenje je, stoga, potrebno kreirati skup podataka koji je označen konzistentno s pravilima koja propisuje iRAP, odnosno koji će koristiti oznake iz sustava FTTS iRAP.

U dogovoru s kreatorima stranice \citep{url:ftts_irap}, izvučeni su podaci geolokacija svih segmenata prometnica na kojima je prisutan atribut pripajanja. 
Segmenti na kojima se određuje je li sigurnosni atribut prisutan ili nije dugački su $10$m.
Također, moguće je i otvoriti videosnimku koja prikazuje trenutak kada započinje segment s atributom pripajanja.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/sattelite_merge_lane_irap.png}
\caption{Prikaz satelitske snimke s označenim segmentom atributa pripajanja (slika preuzeta s \citep{url:google_maps})}
\label{img:sattelite_merge_lane_irap}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/video_merge_lane_irap.png}
\caption{Prikaz videosnimke s označenim segmentom atributa pripajanja sa slike \ref{img:sattelite_merge_lane_irap} (slika preuzeta s \citep{url:ftts_irap})}
\label{img:video_merge_lane_irap}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/sattelite_merge_lane_irap2.png}
\caption{Prikaz satelitske snimke s označenim segmentom atributa pripajanja (slika preuzeta s \citep{url:google_maps})}
\label{img:sattelite_merge_lane_irap2}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/video_merge_lane_irap2.png}
\caption{Prikaz videosnimke s označenim segmentom atributa pripajanja sa slike \ref{img:sattelite_merge_lane_irap2} (slika preuzeta s \citep{url:ftts_irap})}
\label{img:video_merge_lane_irap2}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/sattelite_merge_lane_irap3.png}
\caption{Prikaz satelitske snimke s označenim segmentom atributa pripajanja (slika preuzeta s \citep{url:google_maps})}
\label{img:sattelite_merge_lane_irap3}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/video_merge_lane_irap3.png}
\caption{Prikaz videosnimke s označenim segmentom atributa pripajanja sa slike \ref{img:sattelite_merge_lane_irap3} (slika preuzeta s \citep{url:ftts_irap})}
\label{img:video_merge_lane_irap3}
\end{figure}

Promotrimo slike \ref{img:sattelite_merge_lane_irap}, \ref{img:sattelite_merge_lane_irap2} i \ref{img:sattelite_merge_lane_irap3}. Na slikama je crvenom linijom označen segment koji je na stranici \citep{url:ftts_irap} prema pravilima koje propisuje iRAP označen kao pripajanje. 
Već sa satelitske snimke je vidljivo kako bi moglo biti problema prilikom detekcije tog atributa zbog nedostatka diskriminativnih značajki koje bi to mogle olakšati.
Slike \ref{img:video_merge_lane_irap}, \ref{img:video_merge_lane_irap2} i \ref{img:video_merge_lane_irap3} redom prikazuju isječke iz videosnimaka u trenutcima kada započinju segmenti sa slika \ref{img:sattelite_merge_lane_irap}, \ref{img:sattelite_merge_lane_irap2} i \ref{img:sattelite_merge_lane_irap3} označeni kao pripajanja. 
Iz same slike je vrlo teško odrediti da je u tom trenutku prisutan atribut pripajanja što pokazuje težinu zadatka koji pokušavamo riješiti.

Problem nedostatka informacije možemo riješiti tako da odluku ne temeljimo na jednoj slici, nego na sekvenci slika koje su prethodile trenutnoj. 
Koristeći sekvencu slika koja prethodi slici označenoj kao početak segmenta označenog kao pripajanje, model će biti u mogućnosti lakše donijeti odluku zbog prisutnosti diskriminativne značajke (karakteristične bijele trake u uzorku).
Prisutnost diskriminativne značajke u sekvenci koja prethodi početku pripajanja vidljiva je i iz satelitske snimke.
Skup podataka s oznakama iz sustava FTTS iRAP iz tog razloga ne sadrži statične, pojedinačne slike, nego sekvence slika.

Skup podataka s oznakama iz sustava FTTS iRAP dobiven je obradom 100 videa preuzetih sa stranice \citep{url:ftts_irap}. 
Ukupan broj dobivenih označenih sekvenci s raspodjelom u podskupove je sljedeći:
\begin{itemize}
 \item podskup za učenje -- 7554 sekvenci, od toga 3777 pozitivnih
 \item podskp za validaciju -- 1720 sekvenci, od toga 860 pozitivnih
 \item podskup za testiranje -- 1642 sekvenci, od toga 821 pozitivnih
\end{itemize}

\noindent Skup je kreiran na način da se iz svake videosnimke uzorkuju pozitivni primjeri na sljedeći način: 
\begin{itemize}
 \item odrede se rasponi sličica videosnimke koji su prema stranici \citep{url:ftts_irap} označeni kao pozitivni (sadrže atribut pripajanja)
 \item za svaku sličicu označenu kao pozitivnu, uzorkuje se i nekoliko sličica unatrag, koje će zajedno činiti jednu pozitivnu sekvencu
\end{itemize}

\noindent Na sličan način uzorkuje se i jednak broj negativnih primjera za one sličice za koje je prema stranici \citep{url:ftts_irap} označeno da ne sadrže atribut pripajanja.
Cjelokupni postupak kreiranja skupa podataka uz konkretne podatke o duljini sekvence bit će opisan u nastavku rada.

\chapter{Metode, modeli i postupci} \label{chapter:methods}
Sustav koji ovaj rad opisuje temelji se na algoritmima dubokog učenja. 
Zadatak koji je potrebno riješiti jest binarna klasifikacija, odnosno određivanje je li atribut pripajanja prisutan u prometnoj sceni.
Model koji rješava zadatak tada možemo prikazati sljedećom funkcijom:

\begin{equation}
 \mathbf{y} = f^*(\mathbf{x}; \boldsymbol{\phi}),
\end{equation}

\noindent gdje je $f^*$ funkcija koju želimo naučiti na podacima. Argumenti funkcije $f^*$ su podatak $\mathbf{x}$ (slika ili sekvenca slika -- isječak videosnimke) te skup slobodnih parametara, $\boldsymbol{\phi}$.
Vrijednost funkcije $f^*$, odnosno $\mathbf{y}$, predstavlja upravo željenu informaciju koja nas zanima -- vjerojatnost da je atribut pripajanja prisutan, odnosno vjerojatnost da atribut pripajanja nije prisutan na prometnoj sceni koja odgovara ulaznom vektoru podataka, $\mathbf{x}$.

Modeli dubokog učenja pretpostavljaju kompozitnu strukturu ulaznih podataka -- npr. čovjek je građen od glave i tijela, glava je građena od očiju, usta, nosa i ušiju; oči su građene od rožnice, zjenice i šarenice; i tako dalje.
Iz tog razloga se nad ulaznim podacima obavljaju višestruke linearne i nelinearne operacije \citep{pdf:duboko_0}.
Funkciju $f^*$ stoga možemo prikazati i na sljedeći način:
$f^*(\mathbf{x}; \boldsymbol{\phi})=f^{(n)}(f^{(n-1)}(...f^{(2)}(f^{(1)}(\mathbf{x}, \boldsymbol{\phi}), \boldsymbol{\phi}), \boldsymbol{\phi}), \boldsymbol{\phi})$ \citep{book:deeplearningbook}.
Pojedine funkcije $f^{(i)}$ predstavljaju slojeve dubokog modela koje obavljaju različite operacije.

Ocjenu prikladnosti funkcije $f^*$ sa slobodnim parametrima $\boldsymbol{\phi}$ možemo mjeriti funkcijom gubitka. 
Funkcija gubitka nam govori koliko dobro naša funkcija sa slobodnim parametrima aproksimira stvarna preslikavanja koja su definirana na skupu podataka za učenje.

Učenje modela, odnosno optimizacija, tada se svodi na pretraživanje za onim skupom slobodnih parametara koji će minimizirati funkciju gubitka nad skupom podataka za učenje.
Optimizacijski postupak koji se koristi je gradijentni spust nad funkcijom gubitka koju deriviramo po slobodnim parametrima modela.

Nastavak rada opisuje korištenu funkciju gubitka, optimizacijsku metodu za učenje modela te tipične slojeve dubokih modela koji se koriste za primjenu u računalnom vidu.
Opisane su i konkretne arhitekture koje su se koristile prilikom provođenja eksperimenata te detaljni postupci kojima su generirani skupovi podataka.

\section{Unakrsna entropija kao funkcija gubitka}
Unakrsna entropija kao funkcija gubitka definira se kao negativni logaritam izglednosti modela nad podacima. Učenjem želimo maksimizirati izglednost parametara nad podacima za učenje, odnosno želimo parametre modela za koje je najizglednije da minimiziraju razliku između funkcije $f$ koju aproksimiramo i aproksimirane funkcije modela $f^*$.

Pretpostavke za izvod unakrsne entropije kao funkcije gubitka su sljedeće:
\begin{itemize}
 \item zadatak koji rješavamo jest zadatak klasifikacije slike u jednu od $k$ različitih klasa
 \item izlazni vektor je dimenzionalnosti $k$ i označava međusobno zavisne vjerojatnosti da ulazni podatak pripada svakoj od $k$ klasa
 \item podaci za učenje su izvučeni iz iste razdiobe i međusobno su nezavisni
\end{itemize}

\noindent Izvedimo unakrsnu entropiju kao funkciju gubitka iz logaritma izglednosti modela nad podacima prema \citep{book:machine_learning}:
\begin{align}
 C &= - \ln \mathcal{L}(\boldsymbol{\phi}, \mathcal{D}) = - \ln (p_{model}(\mathcal{D} | \boldsymbol{\phi})) \nonumber \\
 &= - \ln \prod_{\mathbf{x} \in \mathcal{D}} \prod_{j=1}^{k} p_{model}(\mathbf{y}_j | \mathbf{x}, \boldsymbol{\phi})^{\mathbf{y}_j} \nonumber \\
 &= - \ln \prod_{\mathbf{x} \in \mathcal{D}} \prod_{j=1}^{k} f_j^*(\mathbf{x})^{\mathbf{y}_j} \nonumber \\
 &= - \sum_{\mathbf{x} \in \mathcal{D}} \sum_{j=1}^{k} \ln (f_j^*(\mathbf{x})) \mathbf{y}_j \label{eq:neg_log_likelihood}
\end{align}
gdje je $k$ dimenzionalnost izlaznog vektora, $\mathbf{y}_j$ je stvarni izlaz (0 ili 1), a $f_j^*(\mathbf{x})$ je vrijednost $j$-te komponente izlaznog vektora za primjer $\mathbf{x}$ iz skupa podataka za učenje.
Vjerojatnost $p_{model}(\mathbf{y}_j | \mathbf{x}, \boldsymbol{\phi})$ predstavlja vjerojatnost oznake primjera. Kako su izlazi modela iz intervala $\left[ 0, 1\right]$,
navedenu vjerojatnost možemo zapisati kao $f_j^*(\mathbf{x})^{\mathbf{y}_j}$.

\section{Gradijentni spust}

Gradijentni spust je iterativni optimizacijski algoritam za minimiziranje vrijednosti funkcije.
U općenitom slučaju, izračun nove vrijednosti argumenta $\phi$ funkcije $y$ čija se vrijednost minimizira, definiran je kao:
\begin{equation}
 \phi_{n+1} = \phi_n - \psi \cfrac{\partial y}{\partial \phi}, \label{eq:gradient_descent}
\end{equation}
gdje je $\psi$ pozitivna, uobičajeno mala konstanta koja kontrolira faktor korekcije parametra.

\noindent U slučaju učenja dubokog modela, izraz \ref{eq:gradient_descent} možemo zapisati kao:
\begin{equation}
 \boldsymbol{\phi}_{n+1} = \boldsymbol{\phi}{_n} - \eta \cfrac{\partial C}{\partial \boldsymbol{\phi}}, \label{eq:gradient_descent_neural}
\end{equation}
gdje je $\boldsymbol{\phi}$ skup slobodnih parametara modela, $\eta$ je parametar algoritma učenja koji nazivamo stopa učenja \engl{learning rate} kojim definiramo koliko će se po iznosu mijenjati parametri prilikom učenja.
Funkcija koju optimiramo je funkcija gubitka, $C$.

Postoje različite varijante osnovnog algoritma za korekciju parametara modela. 
Korekciju parametara moguće je vršiti akumulirajući gradijent parametara po svim primjerima iz skupa za učenje, gdje govorimo o stvarnom gradijentu nad funkcijom gubitka, $C$. 
Akumulirani gradijent se zatim koristi za korekciju parametara prema izrazu \ref{eq:gradient_descent_neural}. U tom slučaju govorimo o klasičnom gradijentnom spustu.

Varijanta u kojoj se gradijent izračunat u svakom primjeru odmah koristi za korekciju parametara naziva se stohastički gradijentni spust. 
Stohastičnost varijante očituje se u tome što ustvari ne računamo stvarni gradijent funkcije gubitka $C$, nego funkcije $C_\mathbf{x}$, koja definira gubitak nad jednim određenim primjerom $\mathbf{x}$ iz skupa za učenje.
Stohastički gradijentni spust pokazuje bolju otpornost na zaglavljivanje u lokalnim optimumima, ali i brže učenje zbog češće korekcije parametara.

Varijanta u kojoj se gradijent akumulira nad određenim brojem primjera, i zatim se koristi za korekciju parametara, naziva se gradijentni spust s mini grupama \engl{mini-batch} \citep{seminar:rela}.

\subsection{Učenje postupkom Adam}
Učenje postupkom Adam je varijanta postupka učenja klasičnim algoritmom gradijentnog spusta.
Za potrebe učenja modela upotrijebljenog u ovom radu upotrijebljeno je učenje postupkom Adam zbog toga što je postupak robusniji i daje bolje rezultate u odnosu na klasični algoritam gradijentnog spusta \citep{article:adam}. 

Učenje postupkom Adam, za razliku od učenja klasičnim algoritmom gradijentnog spusta, kombinira dvije napredne tehnike prilikom korekcije parametara. 
Algoritam kombinira metode momenta i adaptivnog pomaka što pospješuje učenje dubokih modela.

Metoda momenta pomaže ubrzanju učenja na način da prilikom korekcije parametara modela u obzir uzima i iznos prethodne korekcije -- samo ime i analogija dolaze iz područja fizike pa metodu možemo poistovjetiti s tromosti tijela.
Korekcija parametara se, u odnosu na izraz \ref{eq:gradient_descent_neural}, definira na sljedeći način:
\begin{align}
\mathbf{v}_{n+1} &= \alpha \mathbf{v}_{n} - \eta \cfrac{\partial C}{\partial \boldsymbol{\phi}} \\
 \boldsymbol{\phi}_{n+1} &= \boldsymbol{\phi}_n + \mathbf{v}_{n+1}
\end{align} 
Parametar $\alpha$ određuje jačinu momenta, odnosno utjecaj prethodne korekcije na trenutnu korekciju.
Osim ubrzanja učenja, moment pospješuje i otpornost na zaglavljivanje u lokalnim optimumima jer je moguće ``preskočiti'' lokalni optimum u koji bismo inače zaglavili slijepo prateći samo iznos gradijenta \citep{book:deeplearningbook} \citep{seminar:rela}.

Metoda adaptivnog pomaka pretpostavlja da je stabilnost gradijenta ovisna o svakoj komponenti parametara koji se optimiraju zbog toga što promjena svake pojedine komponente parametara može drugačije utjecati na promjenu iznosa funkcije gubitka koja se optimira.
Iz tog razloga, smisleno je koristiti zasebne stope učenja za svaku od njih i automatski im mijenjati vrijednost kroz postupak učenja, ovisno o tome kako se pojedina komponenta gradijenta mijenja.
Konačan efekt jest da će se komponente parametara čije su parcijalne derivacije po funkciji gubitka vrlo visokih vrijednosti korigirati sa značajno manjim stopama učenja, a komponente parametara čije su parcijalne derivacije po funkciji gubitka relativno niskih vrijednosti, korigirat će se većim stopama učenja \citep{book:deeplearningbook} \citep{seminar:rela}.
Efekt se postiže skaliranjem vrijednosti gradijenata akumuliranim eksponencijalnim pomičnim prosjekom \engl{exponential moving average} što je vidljivo u pseudokodu algoritma \ref{alg:adam}. 
Takvim skaliranjem će gradijenti koji su veći po iznosu biti skalirani većim vrijednostima čime će njihov konačan iznos biti kontroliran.

\begin{algorithm}[H]
\caption{Učenje postupkom Adam}
\label{alg:adam}
\begin{algorithmic}
\STATE inicijalne vrijednosti:
\STATE $t_0 = 0$ 
\STATE  $\mathbf{m}_0 = \vec{0}$
\STATE  $\mathbf{v}_0 = \vec{0}$
\STATE osvježavanje parametara
\STATE $\mathbf{g}_t = \cfrac{\partial C}{\partial \boldsymbol{\phi}_t}$
\STATE $\mathbf{m}_t = \beta_1 \mathbf{m}_{t-1} + (1 - \beta_1) \mathbf{g}_t$
\STATE $\mathbf{v}_t = \beta_2 \mathbf{v}_{t-1} + (1 - \beta_2) \mathbf{g}_t^2$
\STATE $\hat{\mathbf{m}_t} = \cfrac{\mathbf{m}_t}{1 - \beta_1^t}$
\STATE $\hat{\mathbf{v}_t} = \cfrac{\mathbf{v}_t}{1 - \beta_2^t}$
\STATE $\boldsymbol{\phi}_{t+1} = \boldsymbol{\phi}_t - \eta \cfrac{\hat{\mathbf{m}_t}}{\sqrt{\hat{\mathbf{v}_t}} + \epsilon}$
\end{algorithmic}
\end{algorithm}

Pseudokod postupka Adam koristi nekoliko hiperparametara: $t$ je vremenski korak koji se inkrementira sa svakom korekcijom parametara, $\eta$ je stopa učenja, $\beta_1$ i $\beta_2$ su faktori korišteni za
eksponencijalni pomični prosjek \engl{exponential moving average}. Preporučene vrijednosti su $\eta=0.001$, $\beta_1=0.9$ i $\beta_2=0.999$ \citep{article:adam}.
Parametar $\epsilon$ služi za izbjegavanje dijeljenja s nulom i postavlja se na vrlo malu vrijednost (npr. $10^{-8}$).


\subsection{Regularizacija modela} \label{subsection:regularization}

Slojevi u dubokim modelima često imaju vrlo velik broj parametara što može dovesti do problema prenaučenosti.
Vrlo česta regularizacijska metoda koja nastoji spriječiti prenaučenost jest regularizacija metodom smanjenja normi parametara \engl{weight decay}.
Regularizacija metodom smanjenja normi parametara mijenja funkciju gubitka koja se optimira tako da uvodi član ovisan o normi parametara, i to na sljedeći način:
\begin{equation}
 C^* = C + \lambda p(\boldsymbol{\phi}),
\end{equation}
gdje je $C^*$ nova funkcija gubitka koju optimiramo, $C$ je originalna funkcija gubitka, $p(\boldsymbol{\phi})$ predstavlja funkciju norme nad parametrima $\boldsymbol{\phi}$, a $\lambda$ je regularizacijski faktor.
Faktor $\lambda$ određuje utjecaj regularizacije -- što je on veći, regularizacija je jača i dobivamo jednostavnije modele koji nisu skloni prenaučenosti.

Motivacija za korištenje regularizacije metodom smanjenja normi parametara leži u tome da će funkcije modela koje imaju niže vrijednosti normi parametara biti zaglađenije, odnosno imat će nižu varijancu što je poželjno za bolju generalizaciju.
Prisjetimo se kako funkciju $f^*$ dubokog modela možemo prikazati kroz višeslojnu strukturu više različitih funkcija kao što je to objašnjeno u poglavlju \ref{chapter:methods}.
Parametri koje regulariziramo metodom smanjenja normi su oni parametri koji su u bilo kojem od slojeva u direktnoj vezi s ulaznim argumentima u funkciju tog sloja.
Razlog tomu je što želimo postići da male promjene vrijednosti na ulazu u bilo koji sloj ne uzrokuju velike promjene vrijednosti na izlazu tog sloja.

Često korištene funkcije norme $p(\boldsymbol{\phi})$ za vektor slobodnih parametara dimenzionalnosti $n$ jesu:
\begin{description}
 \item [L1 norma] $p(\boldsymbol{\phi})=\sum_{i=1}^n \left| \boldsymbol{\phi}_i \right|$ --- L1 \engl{Lasso} regularizacija
 \item [L2 norma] $p(\boldsymbol{\phi})=\sqrt{\sum_{i=1}^n  \boldsymbol{\phi}_i^2 }$ --- L2 \engl{Ridge} regularizacija
\end{description}
Regularizacija L2 normom parametara je najčešće korištena zbog lakšeg izračuna izraza parcijalne derivacije za korak gradijentnog spusta.

\section{Tipični slojevi dubokih modela za primjenu u računalnom vidu}
Duboki modeli, koji se koriste za primjenu u računalnom vidu, tipično su građeni od nekoliko različitih slojeva koji imaju različite uloge.
Slojevi obavljaju različite operacije nad podacima i tako ostvaruju željenu konačnu funkcionalnost koja je potrebna da se obavi neki zadatak.

\subsection{Potpuno povezani sloj}
Operacija koju obavlja potpuno povezani sloj definirana je na sljedeći način:

\begin{equation}
 \mathbf{y}=g(\mathbf{W}\mathbf{x}),
\end{equation}

\noindent gdje je $\mathbf{x}$ vektor ulaznih podataka, $g$ je aktivacijska funkcija, a  $\mathbf{y}$ je vektor izlaznih podataka. 
Vektor ulaznih podataka obično se proširuje na oblik $\mathbf{x} = \begin{bmatrix} 1 & x_1 & x_2 & ... & x_n \end{bmatrix}^T$.
Vrijednost $\mathbf{x}_1$ se fiksno postavlja na vrijednost $1$ iz razloga što želimo dozvoliti da model modelira pomak parametrima prvog stupca matrice $\mathbf{W}$.
Primijetimo kako će upravo dimenzionalnost matrice $\mathbf{W}$ određivati dimenzionalnost vektora izlaznih podataka.

Aktivacijska funkcija $g$ djeluje po elementima vektora dobivenog operacijom matričnog množenja matrice $\mathbf{W}$ i vektora ulaznih podataka $\mathbf{x}$.
Tipično se koriste nelinearne aktivacijske funkcije kako bismo dobili veću ekspresivnost dubokog modela.
Postoje različite aktivacijske funkcije koje se u praksi koriste. U nastavku su opisane neke od njih.

\subsubsection{Sigmoidalna aktivacijska funkcija}
Sigmoidalna aktivacijska funkcija i njena derivacija definirane su kao: 
\begin{align}
 g^{(i)}_j(\mathbf{x})&=\cfrac{1}{1+e^{-\alpha x_j}}, \\
 \frac{dg^{(i)}(\mathbf{x})}{d\mathbf{x}}&=\alpha g^{(i)}(\mathbf{x}) (1-g^{(i)}(\mathbf{x})) \label{eq:sigmoid_derivative}
\end{align}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/sigmoid_graph.png}
\caption{Graf sigmoidalne aktivacijske funkcije}
\label{img:sigmoid_graph}
\end{figure}

\noindent Sigmoidalna aktivacijska funkcija preslikava ulaznu vrijednost na vrijednost iz intervala $\left< 0, 1\right>$. Sigmoidalna aktivacijska funkcija je derivabilna na cijeloj domeni i njenim korištenjem dobivamo nelinearne modele. 
Slika \ref{img:sigmoid_graph} prikazuje graf sigmoidalne aktivacijske funkcije. 
Iz njega je vidljivo kako će gradijent za većinu vrijednosti sigmoidalne funkcije biti vrlo nizak zbog toga što je vrijednost sigmoidalne funkcije gotovo na cijeloj domeni u zasićenju \engl{saturating function} -- asimptotski se približava vrijednosti 0 ili 1.
Kako je ranije navedeno, učenje modela obavljamo koristeći gradijentni spust funkcije gubitka po parametrima modela. 
Uglavnom nizak iznos gradijenta utječe na to da će već u zadnjem, izlaznom sloju, korekcije parametara modela biti vrlo male. 
Kako izračun korekcija propagiramo unatrag, slojevi koji su sve dalje od završnog sloja imat će sve manje iznose korekcija, što će uvelike utjecati na brzinu i kvalitetu učenja, koje će se drastično smanjiti.
Sigmoidalne aktivacijske funkcije se u praksi zato ne koriste u dubokim modelima \citep{seminar:rela}.

\subsubsection{Po dijelovima linearna aktivacijska funkcija}
Po dijelovima linearna aktivacijska funkcija, ReLU \engl{Rectified Linear Unit} i njena derivacija definirane su kao:
\begin{align}
 g^{(i)}_j(\mathbf{x})&=\left\{
 \begin{array}{ll}
 0,  & \mbox{ako je } x_j < 0 \\
 x_j, & \mbox{ako je } x_j \geq 0 
 \end{array}
 \right. , \\
 \frac{dg^{(i)}_j(\mathbf{x})}{d\mathbf{x}}&=\left\{
 \begin{array}{ll}
 0,  & \mbox{ako je } x_j < 0 \\
 1, & \mbox{ako je } x_j \geq 0 
 \end{array}
 \right.
\end{align}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/relu_graph.png}
\caption{Graf po dijelovima linearne aktivacijske funkcije}
\label{img:relu_graph}
\end{figure}

\noindent Po dijelovima linearna aktivacijska funkcija predstavlja funkciju praga na vrijednosti $0$ ispod koje izlazne vrijednosti nisu propuštene.
Po dijelovima linearna aktivacijska funkcija je često korištena u dubokim modelima zbog zanimljivih svojstava koja pokazuje prilikom učenja takvih struktura.
Vrijednost gradijenta je kod po dijelovima linearne aktivacijske funkcije konstantna za polovicu cijele njene domene. 
U drugoj polovici iznosi $0$, što ponekad također može biti problem jer može dovesti do mrtvih dijelova slojeva kojima se parametri nikako ne korigiraju.
Problem mrtvih dijelova slojeva može se riješiti korištenjem tzv. leaky ReLU prijenosne funkcije koja dopusti mali iznos gradijenta kada je vrijednost aktivacije $0$ \citep{book:deeplearningbook} \citep{seminar:rela}.

\subsubsection{Normalizirajuća eksponencijalna aktivacijska funkcija}
Normalizirajuća eksponencijalna aktivacijska funkcija \engl{softmax} i njena derivacija definirane su kao:
\begin{align}
 g^{(i)}_j(\mathbf{x})&=\cfrac{e^{x_j}}{\sum_{k=1}^{n} e^{x_k}}, \\
 \frac{dg^{(i)}_j(\mathbf{x})}{\mathbf{x}}&=\left\{
 \begin{array}{ll}
 g^{(i)}_j(\mathbf{x}) (1-g^{(i)}_j(\mathbf{x})),  & \mbox{ako je } j = k \\
 -g^{(i)}_j(\mathbf{x}) g^{(i)}_k(\mathbf{x}), & \mbox{ako je } j \neq k 
 \end{array}
 \right.
\end{align}
Normalizirajuća eksponencijalna aktivacijska funkcija je generalizacija sigmoidalne funkcije u smislu da proširuje sigmoidalnu funkciju namijenjenu binarnoj klasifikaciji na klasifikaciju s $n$ klasa.

Normalizirajuća eksponencijalna aktivacijska funkcija preslikava $n$ - dimenzionalni vektor realnih vrijednosti u $n$ - dimenzionalni vektor realnih vrijednosti koje se zbrajaju u vrijednost $1$.
Takav vektor realnih vrijednosti možemo promatrati kao vjerojatnosnu razdiobu i upravo iz tog razloga se normalizirajuća eksponencijalna aktivacijska funkcija često koristi u posljednjem sloju dubokih modela za probleme klasifikacije -- daje nam vjerojatnost s kojom ulazni uzorak pripada svakoj od $n$ mogućih klasa, slično kao što je sigmoidalna aktivacijska funkcija korištena kod binarne klasifikacije logističkom regresijom \citep{seminar:rela}.

\subsection{Konvolucijski sloj}
Konvolucijski slojevi koriste se za stvaranje mapa značajki uporabom dvodimenzionalne konvolucije jezgre s podacima.
Za definiciju konvolucije potrebno je prvo definirati veličinu jezgre (širinu i visinu), vrijednosti parametara jezgre te pomak jezgre po širini, odnosno po visini prilikom izračuna.
\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{images/convolution.png}
\caption{Dva koraka konvolucije s dvodimenzionalnim podacima}
\label{img:convolution}
\end{figure}
Slika \ref{img:convolution} prikazuje dva koraka konvolucije podataka s jezgrom. Slika a) prikazuje prvi korak konvolucije, a slika b) drugi korak. 
U oba koraka veličina jezgre je $3x3$, a korak iznosi $1$. 
Korak konvolucije \engl{stride} određuje pomak prozora po širini, odnosno visini ulazne mape značajki. 

Općenito, vrijednost jednog elementa mape značajki u sloju $l$, dobivene konvolucijom nad jednom ulaznom mapom značajki iz sloja $l-1$ definiramo kao:
\begin{equation}
 x^l_{i,j}=\sum_{m,n=0}^{m=K_w,n=K_h}x^{l-1}_{i \cdot s_w +m, j \cdot s_h +n} w^l_{m, n}, \label{eq:convolution}
\end{equation}
gdje je $x_{i,j}^l$ vrijednost mape značajki u sloju $l$, za redak $i$ i stupac $j$. $K_w$ je širina jezgre, $K_h$ je visina jezgre, a $w^l_{m,n}$ vrijednost parametara jezgre za redak $m$ i stupac $n$.
Vrijednosti $s_w$ i $s_h$ predstavljaju pomak po širini, odnosno visini.

Izraz \ref{eq:convolution} opisuje izračun vrijednosti jednog elementa mape značajke koji je linearna kombinacija vrijednosti samo jedne mape značajki prethodnog sloja.
U konvolucijskim arhitekturama se općenito koriste mape značajki koje su povezane s većim brojem mapa značajki iz prethodnog sloja.
Za svaku od mapa značajki s kojom je povezana postoji po jedna jezgra koja se koristi za izračun vrijednosti.
Primjerice, jedna mapa značajki ulaznog sloja može biti povezana s 3 mape značajki - crvenom, plavom i zelenom komponentom slike u boji.
Za svaku od komponenanta boja će mapa značajki imati drukčiju jezgru.

Nadalje, izračun vrijednosti mapa značajki se često generalizira kao i kod potpuno povezanog sloja pa se dodaje dodatan parametar kao vrijednost praga te se koriste aktivacijske funkcije.
Generalizirani izraz za izračun vrijednosti jednog elementa mape značajki u sloju $l$, dobivene konvolucijom odgovarajućih jezgara sa svakom od mapa značajki iz sloja $l-1$ s kojima je povezana definiramo kao:
\begin{equation}
 x^l_{k',i,j}=\sigma\left(\sum_{k\in F^{l-1}}\sum_{m,n=0}^{m=K_w^k,n=K_h^k}x^{l-1}_{k, i \cdot s_w +m, j \cdot s_h +n} w^l_{k, m, n} + b^l\right), \label{eq:generalized_convolution}
\end{equation}
gdje je $x_{k,i,j}^l$ vrijednost mape značajki $k$ u sloju $l$, za redak $i$ i stupac $j$. 
$F^{l-1}$ je skup mapa značajki iz sloja $l-1$ s kojima je mapa značajki iz sloja $l$ povezana. 
$K_w^k$ je širina jezgre, a $K_h^k$ je visina jezgre za mapu značajki $k$ iz sloja $l-1$. 
$w^l_{k, m, n}$ je vrijednost parametara jezgre za mapu značajki $k$ iz sloja $l-1$ za redak $m$ i stupac $n$.
Vrijednosti $s_w$ i $s_h$ predstavljaju pomak po širini, odnosno visini.
Vrijednost $b^l$ predstavlja vrijednost praga za mapu značajki iz sloja $l$. 
U pravilu se vrijednost praga dijeli za cijelu mapu značajki, no to nije nužno te je moguće za svaku od mapa značajki iz prethodnog sloja imati po jednu vrijednost praga.
Konačno, funkcija $\sigma$ predstavlja aktivacijsku funkciju.

Zbog svojih svojstava, konvolucijski slojevi mogu uvelike poboljšati učinkovitost modela za klasifikaciju slika.
Konvolucijski slojevi su tipično rijetko povezani -- nije nužno da su sve mape značajki sloja $l-1$ povezane sa svakom od mapa značajki iz sloja $l$ \citep{book:deeplearningbook}, što, uz jezgre koje su tipično mnogo manjih veličina od ulaza nad kojima djeluju, u velikoj mjeri smanjuje broj parametara i povećava efikasnost učenja i računanja.
Potpuno povezani slojevi koriste matrično množenje i svaki parametar je iskorišten samo jednom za opisivanje veze između ulaza i izlaza, dok se konvolucijom isti parametri koriste za više lokacija ulaza i predstavljaju svojevrsne značajke koje jezgra izlučuje na slici.
Konvolucijske arhitekture korištenjem jezgara s dijeljenim parametrima uče skup parametara koji je otporan na translacije, jer će za iste ulazne vrijednosti jezgra dati iste izlazne vrijednosti, bez obzira gdje na slici se one pojave. 
Naučeni dijeljeni skup parametara predstavlja jednu funkciju koju jezgra obavlja (primjerice, detekcija rubova) -- učenjem se skup parametara prilagođava cijeloj slici i uči se tako da obavlja apstraktne funkcije neovisne o lokaciji slike, a koje će pripomoći u samoj klasifikaciji.
Nabrojana svojstva konvolucijske arhitekture donose svojevrsnu ugrađenu regularizaciju, što povlači bolju generalizaciju uz veću efikasnost \citep{book:deeplearningbook} \citep{masters:vukotic_ms} \citep{seminar:rela}.

\subsection{Sloj sažimanja}
Slojevi sažimanja koriste se da se grupira određeni broj podataka mape značajki i predstavi ih kao jedan podatak koji statistički dobro predstavlja tu grupu.
Sam postupak također smanjuje veličinu mapa značajki, i to tako da ih skalira faktorom $\cfrac{1}{S_w}$ po širini, odnosno faktorom $\cfrac{1}{S_h}$ po visini, gdje je $S_w$ širina, a $S_h$ visina podmape značajki koja se grupira.

Korisnost postupka očituje se u vidu ostvarivanja invarijantnosti na lokalne translacije što može biti vrlo korisno u slučaju da nam je važnije da je neka značajka prisutna od toga na kojoj je točno lokaciji \citep{seminar:rela}.

Postoje različite vrste funkcija koje se koriste za sažimanje, od kojih je u ovom radu korišteno sažimanje maksimalnom vrijednošću.
Sažimanje maksimalnom vrijednošću \engl{max-pooling} sažima značajke tako da iz podmape značajki nad kojom djeluje izluči samo maksimalnu vrijednost koja postaje predstavnik.
Pokazuje se da se ovom metodom dobivaju vrlo dobri rezultati \citep{article:maxpooling_article}.

\subsection{Sloj grupne normalizacije \engl{batch normalization}}
Učenje dubokih modela može biti vrlo komplicirano ukoliko bolje promotrimo njihovu arhitekturu, način učenja i sam utjecaj načina učenja na brzinu učenja.
Učenjem mijenjamo parametre modela, a samim time, promjenom parametara u određenom sloju modela, mijenjamo distribuciju ulaznih podataka koje dobiva idući sloj.
Sama dubina dodatno uvećava utjecaj promjena parametara modela -- distribucija ulaza svakog sloja uvjetovana je promjenama na parametre modela svih slojeva koji mu prethode.

Konstantna promjena distribucije ulaza slojeva predstavlja problem jer je potrebno stalno se prilagođavati na novu distribuciju, što može uvelike usporiti učenje.
Opisani problem nazivamo interni kovarijacijski pomak \engl{internal covariate shift}. 
Metoda grupne normalizacije \engl{Batch Normalization} uklanja taj problem i uvelike ubrzava učenje dubokih modela.

Uklanjanje problema internog kovarijacijskog pomaka rješavamo normalizacijom ulaza svakog sloja -- linearno ga transformiramo tako da mu je srednja vrijednost jednaka 0, a varijanca mu je jednaka 1.
Direktna normalizacija ulaza i izlaza nekog sloja ovisi o statistici svih ulaza tog sloja nad kompletnim skupom podataka nad kojim učimo model.
Zbog izrazite računske složenosti koja bi bila potrebna za to, uvode se neka pojednostavljenja.

Prva pretpostavka za pojednostavljenje složenosti jest da umjesto normalizacije ulaza i izlaza združeno, normaliziramo svaku komponentu ulaza zasebno, s pretpostavkom da komponente nisu međusobno zavisne.
Normalizacija $k$-te komponente ulaznog vektora $\mathbf{x}$ nekog sloja definirana je na sljedeći način:
\begin{equation}
 \hat{\mathbf{x}}_{k} = \cfrac{\mathbf{x}_{k} - \mathop{\mathbb{E}} \left[ \mathbf{x}_{k} \right]} {\sqrt{ \mathrm{Var} \left[ \mathbf{x}_{k} \right] } }, \label{eq:bn_normalization}
\end{equation}
gdje su očekivanje i varijanca izračunati nad skupom podataka za učenje.
Normalizacija svakog ulaza nekog sloja može promijeniti njegovu ekspresivnu snagu pa iz tog razloga uvodimo transformaciju normaliziranog ulaza kojom osiguravamo da je iz normaliziranih ulaznih podataka moguće dobiti originalne vrijednosti.
Transformacija $k$-te komponente prethodno normaliziranog ulaznog vektora $\hat{\mathbf{x}}$ nekog sloja definirana je na sljedeći način:
\begin{equation}
 \mathbf{y}_{k} = \boldsymbol{\gamma}_{k} \hat{\mathbf{x}}_{k} + \boldsymbol{\beta}_{k}, \label{eq:bn_transformation}
\end{equation}
gdje su $\boldsymbol{\gamma}_{k}$ i $\boldsymbol{\beta}_{k}$ parametri koji se uče zajedno s parametrima modela i koji omogućuju skaliranje i pomak normalizirane vrijednosti izlaza.

Druga pretpostavka za pojednostavljenje složenosti jest da normalizaciju, umjesto nad statistikom cjelokupnog skupa podataka za učenje, obavljamo nad statistikama malih podskupova podataka \engl{mini-batch}.
Grupna normalizacija nad statistikom malog podskupa skupa podataka za učenje u nekom sloju tada je definirana kao normalizacija i linearna transformacija ulaza, definirane u izrazima \ref{eq:bn_normalization} i \ref{eq:bn_transformation}.

Transformacija grupne normalizacije najčešće se koristi nad izračunatim težinskim sumama slojeva, prije djelovanja aktivacijske funkcije.
Normalizirane vrijednosti $\hat{\mathbf{x}}_{k}$ možemo promatrati kao ulaze u podsloj kojem je funkcija linearna, i to je upravo funkcija transformacije definirana u izrazu \ref{eq:bn_transformation}.
Na izlaz podsloja tada djeluje procesiranje originalnog sloja. 
Takvom arhitekturom ostvarili smo da svi podslojevi na ulaze dobivaju podatke s fiksnom distribucijom (s očekivanjem 0 i varijancom 1), što ubrzava učenje podslojeva, a time posljedično i samih slojeva i kompletnog modela \citep{article:bn_paper} \citep{seminar:rela}.

\section{Arhitekture korištene u eksperimentima}
U poglavlju \ref{chapter:skupovi_podataka} opisana su dva tipa skupova podataka korištenih za eksperimente -- skup podataka sa statičnim slikama i skup podataka sa sekvencama slika.
Korišteno je nekoliko različitih modela koji su zasnovani na arhitekturi VGG-16 \citep{article:vgg} treniranoj za natjecanje ILSVRC-2014 \citep{article:ilsvrc2015}.
Model VGG-16 treniran je za klasifikaciju slika u 1000 različitih klasa na vrlo velikom broju slika -- 1.3 milijuna \citep{article:vgg}.
Pokazuje se da model iz tog razloga vrlo dobro generalizira i na drugim problemima \citep{article:vgg} pa je iz tog razloga odabran kao baza modela korištenih za eksperimente u ovom radu.

\subsection{Arhitektura VGG-16 modela}
\begin{figure}[H]
\centering
\includegraphics[scale=0.65]{images/vgg_architecture.png}
\caption{Arhitektura VGG-16 modela (slika preuzeta i prerađena iz \citep{article:vgg_architecture})}
\label{img:vgg_architecture}
\end{figure}
Slika \ref{img:vgg_architecture} prikazuje originalnu arhitekturu VGG-16 građenu od 16 slojeva.

Prednji dio sastoji se od 5 konvolucijskih blokova. 
Svaki od blokova izgrađen je na sličan način -- nekoliko konvolucijskih slojeva iza kojih slijedi sloj za sažimanje maksimalnom vrijednošću \engl{max pool}.
Konvolucijski slojevi imaju jezgre dimenzija $3$ x $3$ uz izlazni korak konvolucije \engl{stride} 1. 
Svi konvolucijski slojevi koriste po dijelovima linearnu funkciju \engl{ReLU} te su regularizirani L2 normom parametara s faktorom regularizacije iznosa $5\cdot10^{-4}$.
Slojevi za sažimanje maksimalnom vrijednošću imaju podmape za grupiranje veličine $2$ x $2$, uz korak uzorkovanja podmapa 2.
Konvolucijski blokovi građeni su kako slijedi:
\begin{itemize}
 \item prvi konvolucijski blok:
 \begin{itemize}
  \item konvolucijski sloj sa 64 izlazne mape značajki
  \item konvolucijski sloj sa 64 izlazne mape značajki
  \item sloj za sažimanje maksimalnom vrijednošću
 \end{itemize}
  \item drugi konvolucijski blok:
 \begin{itemize}
  \item konvolucijski sloj sa 128 izlaznih mapa značajki
  \item konvolucijski sloj sa 128 izlaznih mapa značajki
  \item sloj za sažimanje maksimalnom vrijednošću
 \end{itemize}
   \item treći konvolucijski blok:
 \begin{itemize}
  \item konvolucijski sloj s 256 izlaznih mapa značajki
  \item konvolucijski sloj s 256 izlaznih mapa značajki
  \item konvolucijski sloj s 256 izlaznih mapa značajki
  \item sloj za sažimanje maksimalnom vrijednošću
 \end{itemize}
    \item četvrti konvolucijski blok:
 \begin{itemize}
  \item konvolucijski sloj s 512 izlaznih mapa značajki
  \item konvolucijski sloj s 512 izlaznih mapa značajki
  \item konvolucijski sloj s 512 izlaznih mapa značajki
  \item sloj za sažimanje maksimalnom vrijednošću
 \end{itemize}
     \item peti konvolucijski blok:
 \begin{itemize}
  \item konvolucijski sloj s 512 izlaznih mapa značajki
  \item konvolucijski sloj s 512 izlaznih mapa značajki
  \item konvolucijski sloj s 512 izlaznih mapa značajki
  \item sloj za sažimanje maksimalnom vrijednošću
 \end{itemize}
\end{itemize}

Stražnji dio građen je od  3 potpuno povezana sloja koji služe za klasifikaciju konvolucijskih reprezentacija dimenzija $7$ x $7$ x $512$ u 1000 različitih klasa. 
Prilikom korištenja arhitekture VGG-16 za druge namjene, obično se uklanja stražnji ili svi potpuno povezani slojevi te se na prednji dio, koji služi za izlučivanje značajki iz ulaznih slika, nadodaju novi slojevi, koji se treniraju za obavljanje specifičnog zadatka.
Ovakva primjena prednaučenih konvolucijskih modela naziva se prijenos znanja \engl{knowledge transfer} \citep{proceeding:transfer_learning}.

\subsection{Arhitektura za klasifikaciju pojedinačnih slika}
Duboki model korišten za klasifikaciju pojedinačnih slika temeljen je na VGG-16 arhitekturi. 
Koristi se naučen prednji dio s 5 konvolucijskih blokova. 
Dobivene izlazne mape značajki pretvaraju se u jednodimenzionalan vektor, koji se zatim vodi na potpuno povezane slojeve definirane kako slijedi:
\begin{itemize}
 \item potpuno povezani sloj dimenzionalnosti 200
 \begin{itemize}
  \item po dijelovima linearna \engl{ReLU} aktivacijska funkcija
  \item grupna normalizacija \engl{batch normalization}
  \item regularizacija L2 normom parametara
 \end{itemize}
 \item potpuno povezani sloj dimenzionalnosti 2 za binarnu klasifikaciju -- određivanje je li atribut prisutan na slici ili nije
 \begin{itemize}
  \item normalizirajuća eksponencijalna \engl{softmax} aktivacijska funkcija
  \item regularizacija L2 normom parametara
 \end{itemize}
\end{itemize}

\subsection{Arhitekture za klasifikaciju sekvenci slika}
Za klasifikaciju sekvenci slika korišteno je nekoliko različitih modela temeljenih na prednaučenoj arhitekturi VGG-16. 
Korišteni modeli su inspirirani arhitekturama iz \citep{article:sequential_architectures}.

Zajednički postupak koji svi modeli dijele jest postupak izlučivanja prostornih značajki -- za svaku sliku sekvence se, koristeći prednji dio prednaučene arhitekture VGG-16, izračunaju značajke, koje se zatim dalje obrađuju na različite načine.
Dobivene prostorne značajke svake pojedine slike su dimenzija $H$ x $W$ x $512$, gdje dimenzije $H$ i $W$ ovise o dimenzijama ulaznih slika, a treća dimenzija je određena brojem izlaznih mapa značajki posljednjeg konvolucijskog sloja arhitekture VGG-16. 

\subsubsection{Klasifikacija sekvenci slika korištenjem vremensko-prostornog sažimanja}
Model koji koristi vremensko-prostorno sažimanje pretvara dobivene prostorne značajke svake slike u jednodimenzionalni vektor dimenzija $H$ x $W$ x $512$.
Dobiveni jednodimenzionalni vektori se zatim oblikuju u dvodimenzionalni tenzor dimenzija $N$ x ($H$ x $W$ x $512$), gdje je $N$ duljina sekvence slika.

Dvodimenzionalni tenzor, koji se dobije povezivanjem prostornih značajki, sadrži i vremenske i prostorne informacije. 
Taj se tenzor zatim obrađuje kroz nekoliko slojeva kako slijedi:
\begin{itemize}
 \item sloj za sažimanje maksimalnom vrijednošću s podmapama za grupiranje veličina $2$ x $2$ uz korak uzorkovanja podmapa 2
 \begin{itemize}
  \item operacija efektivno provodi vremensko-prostorno sažimanje značajki koje su bliske vremenski i prostorno
 \end{itemize}
 \item pretvaranje dobivenog dvodimenzionalnog tenzora u jednodimenzionalni
 \item potpuno povezani sloj dimenzionalnosti 200
 \begin{itemize}
  \item po dijelovima linearna \engl{ReLU} aktivacijska funkcija
  \item grupna normalizacija \engl{batch normalization}
  \item regularizacija L2 normom parametara
 \end{itemize}
 \item potpuno povezani sloj dimenzionalnosti 2 za binarnu klasifikaciju -- određivanje je li atribut prisutan na slici ili nije
 \begin{itemize}
  \item normalizirajuća eksponencijalna \engl{softmax} aktivacijska funkcija
  \item regularizacija L2 normom parametara
 \end{itemize}
\end{itemize}

\subsubsection{Klasifikacija sekvenci slika korištenjem povratnih LSTM ćelija \engl{Long Short Term Memory}}
LSTM ćelije pogodne su za korištenje nad sekvencama podataka jer sadrže memorijske ćelije u kojima mogu čuvati informacije kroz dugačke vremenske periode.

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{images/lstm_input.png}
\caption{Arhitektura jednoslojne LSTM ćelije (slika nacrtana prema \citep{article:lstm})}
\label{img:lstm_input}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{images/lstm_hidden.png}
\caption{Arhitektura s više slojeva LSTM ćelija (slika nacrtana prema \citep{article:lstm})}
\label{img:lstm_hidden}
\end{figure}

Slika \ref{img:lstm_input} prikazuje arhitekturu jednoslojne LSTM ćelije koja kao ulaz dobiva ulazni podatak. 
Slika \ref{img:lstm_input} prikazuje arhitekturu s više slojeva LSTM ćelija u kojoj je izlaz LSTM ćelije prethodnog sloja ulaz LSTM ćeliji idućeg sloja.

U svakom vremenskom koraku potrebno je izračunati izlaz LSTM ćelije i novi sadržaj memorijske ćelije.
Izlaz LSTM ćelije i novi sadržaj memorijske ćelije računaju se na temelju tri vektora:
\begin{itemize}
 \item ulaznom podatku trenutnog vremenskog koraka, odnosno izlazu LSTM ćelije prethodnog sloja trenutnog vremenskog koraka -- $\mathbf{x}_t$ na slici \ref{img:lstm_input}, odnosno $\mathbf{h}^{1}_t$ na slici \ref{img:lstm_hidden}
 \item izlazu LSTM ćelije trenutnog sloja za prethodni vremenski korak  -- $\mathbf{h}_{t-1}$  na slici \ref{img:lstm_input}, odnosno $\mathbf{h}_{t-1}^1$ i $\mathbf{h}_{t-1}^2$ na slici \ref{img:lstm_hidden}
 \item sadržaju memorijske ćelije trenutnog sloja za prethodni vremenski korak -- $\mathbf{c}_{t-1}$ na slici \ref{img:lstm_input}, odnosno $\mathbf{c}_{t-1}^1$ i $\mathbf{c}_{t-1}^2$ na slici \ref{img:lstm_hidden}
\end{itemize}
U općenitom slučaju višeslojne arhitekture LSTM ćelija, izlaz i novi sadržaj memorijske ćelije računaju se sljedećim izrazima:
\begin{align}
 \text{stanje ćelije: } \mathbf{c}_t^l &= \mathbf{f} \odot \mathbf{c}_{t-1}^l + \mathbf{i} \odot \mathbf{g} \\
 \text{izlaz ćelije: } \mathbf{h}_t^l &= \mathbf{o} \odot \tanh(\mathbf{c}^l_t) \\
 \text{vektor ulaznih vrata: } \mathbf{i} &= \sigma (\mathbf{W}_i [\mathbf{h}^{l}_{t-1}, \mathbf{h}^{l-1}_t] + \mathbf{b}_i) \\
 \text{vektor vrata zaboravljanja: } \mathbf{f} &= \sigma (\mathbf{W}_f [\mathbf{h}^{l}_{t-1}, \mathbf{h}^{l-1}_t] + \mathbf{b}_f) \\
 \text{vektor izlaznih vrata: } \mathbf{o} &= \sigma (\mathbf{W}_o [\mathbf{h}^{l}_{t-1}, \mathbf{h}^{l-1}_t] + \mathbf{b}_o) \\
 \text{vektor ulaznih modulacijskih vrata: } \mathbf{g} &= \sigma (\mathbf{W}_g [\mathbf{h}^{l}_{t-1}, \mathbf{h}^{l-1}_t] + \mathbf{b}_g), 
\end{align}
gdje je $\tanh$ aktivacijska funkcija tangens hiperbolni, $\sigma$ je sigmoidalna aktivacijska funkcija, $\odot$ je operator množenja koji djeluje po elementima, a $[\mathbf{x}, \mathbf{y}]$ je operacija spajanja vektora $\mathbf{x}$ dimenzija $n_1$ i vektora $\mathbf{y}$ dimenzija $n_2$ u vektor dimenzija $n_1 + n_2$.
Notacija $\mathbf{h}^{l}_{t}$ predstavlja izlazni vektor LSTM ćelije vremenskog trenutka $t$ u sloju $l$.

Model koji koristi LSTM ćelije prostorne značajke svake slike pretvori u jednodimenzionalni vektor dimenzija $H$ x $W$ x $512$.
Dobiveni jednodimenzionalni vektori se zatim redom obrađuju kako slijedi:
\begin{itemize}
 \item LSTM sloj sa stanjem dimenzionalnosti 128
 \item LSTM sloj sa stanjem dimenzionalnosti 64
 \item LSTM sloj sa stanjem dimenzionalnosti 32
  \item potpuno povezani sloj dimenzionalnosti 2 za binarnu klasifikaciju -- određivanje je li atribut prisutan na slici ili nije
 \begin{itemize}
  \item ulaz u ovaj potpuno povezani sloj jest posljednji izlaz dobiven iz LSTM ćelije prethodnog sloja koja je obradila cijelu sekvencu podataka (vektor dimenzionalnosti 32)
  \item normalizirajuća eksponencijalna \engl{softmax} aktivacijska funkcija
  \item regularizacija L2 normom parametara
 \end{itemize}
\end{itemize}


\subsubsection{Klasifikacija sekvenci slika korištenjem vremenskog potpuno povezanog sloja}
Model koji koristi vremenski potpuno povezani sloj, prostorne značajke pretvori u jednodimenzionalni vektor dimenzija $H$ x $W$ x $512$.
Svaki dobiveni jednodimenzionalni vektor prostornih značajki se zatim obrađuje kako slijedi:
\begin{itemize}
  \item potpuno povezani sloj dimenzionalnosti 64
 \begin{itemize}
  \item po dijelovima linearna \engl{ReLU} aktivacijska funkcija
  \item grupna normalizacija \engl{batch normalization}
  \item regularizacija L2 normom parametara
  \item ovaj potpuno povezani sloj služi za predstavljanje prostornih značajki vektorom manjih dimenzija
 \end{itemize}
\end{itemize}
Jednodimenzionalni vektori dobiveni nakon potpuno povezanog sloja se zatim oblikuju u dvodimenzionalni tenzor dimenzija $N$ x $64$, gdje je $N$ duljina sekvence slika.
Taj se tenzor zatim obrađuje kroz nekoliko slojeva kako slijedi:
\begin{itemize}
 \item pretvaranje dobivenog dvodimenzionalnog tenzora u jednodimenzionalni
 \item potpuno povezani sloj dimenzionalnosti 64
 \begin{itemize}
  \item po dijelovima linearna \engl{ReLU} aktivacijska funkcija
  \item grupna normalizacija \engl{batch normalization}
  \item regularizacija L2 normom parametara
  \item ovaj potpuno povezani sloj služi za povezivanje dobivenih prostornih značajki po dimenziji vremena
 \end{itemize}
 \item potpuno povezani sloj dimenzionalnosti 2 za binarnu klasifikaciju -- određivanje je li atribut prisutan na slici ili nije
 \begin{itemize}
  \item normalizirajuća eksponencijalna \engl{softmax} aktivacijska funkcija
  \item regularizacija L2 normom parametara
 \end{itemize}
\end{itemize}

\section{Postupak pripreme skupova podataka}
Poglavlje \ref{chapter:skupovi_podataka} opisuje dva tipa skupova podataka korištenih u ovom radu.
U nastavku je opisan postupak pretprocesiranja slika koje se dobivaju iz georeferenciranih videosnimaka sa stranice \citep{url:ftts_irap} te postupak kreiranja skupa podataka s oznakama iz sustava FTTS iRAP.

\subsection{Pretprocesiranje slika}
Slike korištene za kreiranje skupova podataka dobivene su iz videosnimaka snimljenih automobilom koji se kretao engleskim autocestama.
Zbog kretnje automobila uzorkovane slike bit će snimljene iz različitog kuta u odnosu na Sunce.
Takva situacija za posljedicu ima da su neke slike mnogo svjetlije, a neke mnogo tamnije od drugih.

Metoda kojom se može ublažiti velika varijacija kontrasta između slika jest metoda adaptivnog izjednačavanja histograma \citep{article:adapt_hist}.
Izjednačavanje histograma za cilj ima izjednačiti razdiobu intenziteta svih kanala slike (crvenog, zelenog i plavog) na način da oni budu uniformno distribuirani.
Metoda adaptivnog izjednačavanja histograma za računanje histograma ne uzima u obzir cijelu sliku nego prozore određene veličine čime se dobiva na lokalnosti izjednačavanja.

\begin{figure}[H]
\centering
\includegraphics[scale=0.2]{images/original.png}
\caption{Originalna slika (slika preuzeta s \citep{url:ftts_irap})}
\label{img:original}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.2]{images/hist.png}
\caption{Slika s izjednačenim histogramom}
\label{img:hist}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.2]{images/adapt_hist.png}
\caption{Slika s adaptivno izjednačenim histogramom}
\label{img:adapt_hist}
\end{figure}

Iz slika \ref{img:original}, \ref{img:hist} i \ref{img:adapt_hist} vidljivo je kako su, u odnosu na originalnu sliku, na slici s adaptivno izjednačenim histogramom najbolje naglašeni detalji zbog najbolje ublažene varijacije kontrasta.
Eksperimentalno je utvrđeno da adaptivno izjednavačanje histograma poboljšava performanse dubokog modela.
Metoda adaptivnog izjednačavanja histograma se iz tog razloga koristi kao korak pretprocesiranja za svaku sliku korištenu prilikom kreiranja skupova podataka.

\subsection{Postupak kreiranja slika s oznakama iz sustava FTTS iRAP}
Kreiranje slika prometnih scena s oznakama iz sustava FTTS iRAP obavlja se automatiziranim postupkom.
Ulazni podaci za automatizirani postupak su sljedeći:
\begin{itemize}
 \item geolokacije na kojima je prisutan atribut pripajanja
 \item popis poveznica na sve video snimke u sustavu \citep{url:ftts_irap}
 \item broj video snimaka koji će se obraditi
\end{itemize}
Postupak će iz ulaznih podataka kreirati sljedeće:
\begin{itemize}
 \item slika s oznakom prisutnosti atributa pripajanja na njoj te sekvenca slika koja joj prethodi (kao što je objašnjeno u poglavlju \ref{chapter:skupovi_podataka})
 \item slika s oznakom prisutnosti atributa pripajanja bez sekvence koja joj prethodi
 \item geolokacije označenih slika i sekvenci slika
\end{itemize}
\noindent Postupak kreira označene slike sa i bez sekvence koja joj prethodi kako bi se eksperimentima ustanovilo dobiva li se na točnosti postupka uvodeći više informacija kroz sekvencu slika.

Geolokacije videosnimaka uzorkovane su rijetko -- najčešće svakih $0.5s$. 
Iz tog razloga se za točnu geolokaciju konkretne sličice videosnimke vrši linearna interpolacija između dvije uzorkovane geolokacije koje su vremenski najbliže konkretnoj sličici.
Geolokacija konkretnih sličica korisna je informacija, jer je prilikom testiranja modela za svaki ulazni podatak kojem model dodijeli krivu oznaku moguće u sustavu FTTS iRAP provjeriti je li osoba koja je dodijelila vrijednost atributa tom segmentu to napravila točno ili je riječ o mogućoj pogrešci. 
Takvim postupkom moguće je na brži način validirati ispravnost dodijeljenih oznaka u sustavu.

Nastavak opisuje sažeti pseudokod automatiziranog postupka:
\begin{algorithm}[H]
\caption{Automatizirano kreiranje slika označenih konzistentno s projektom FTTS iRAP}
\label{alg:dataset_creator}
\begin{algorithmic}
\WHILE{nije obrađen željen broj video snimaka}
\STATE v=preuzmi\_video()
\STATE geolok,vrem=preuzmi\_geolokacije\_i\_vremena(v)
\STATE sl=kreiraj\_sličice(v)
\STATE ind\_geolok,brz\_aut=indeksiraj\_geolokacije\_i\_izračunaj\_brzine\_automobila(geolok,vrem)
\STATE ras\_poz=izračunaj\_raspone\_pozitiva(geolok\_pripajanja,ind\_geolok,brz\_aut)
\STATE poz\_slič,geolok\_slič=kreiraj\_pozitivne\_sličice\_s\_geolokacijama(ras\_poz,sl)
\STATE pohrani\_sličice(poz\_slič,geolok\_slič)
\STATE neg\_slič,geolok\_slič=kreiraj\_negativne\_sličice\_s\_geolokacijama(ras\_poz,sl)
\STATE pohrani\_sličice(neg\_slič,geolok\_slič)
\ENDWHILE
\end{algorithmic}
\end{algorithm}

\noindent Izračunavanje raspona sličica na kojima je prisutan atribut pripajanja (pozitivne sličice) radi se na sljedeći način:
\begin{itemize}
 \item za svako pripajanje i njegovu geolokaciju pronađu se dvije najbliže geolokacije videosnimke
 \item ukoliko je bliža geolokacija videosnimke unutar praga udaljenosti pripajanju, uzima se da je pripajanje prisutno na tom dijelu videosnimke
 \item na temelju udaljenosti geolokacija videosnimke od geolokacije pripajanja i brzina kretanja automobila izračuna se točan raspon vremena videosnimke na kojem se nalazi segment atributa pripajanja
 \item iz dobivenog raspona vremena izračuna se raspon sličica videosnimke na kojem se nalazi segment atributa pripajanja
\end{itemize}

\chapter{Eksperimenti i rezultati}
Za potrebe ovog rada provedeno je nekoliko eksperimenata. 
Postupak učenja i testiranja u svakom eksperimentu je jednak, razlikuju se samo u vrsti ulaznih podataka (statične slike ili sekvence slika) te u korištenoj arhitekturi.
U eksperimentima u kojima su korištene sekvence slika, duljina sekvence je eksperimentalno utvrđena i postavljena na 25 sličica.

\section{Način učenja i testiranja u eksperimentima}
Početni korak prilikom učenja jest normalizacija skupa podataka.
Kako su podaci slike u boji, na podacima za treniranje se izračunava srednja vrijednost intenziteta piksela za svaki od kanala -- crveni, zeleni i plavi.
Dobivene srednje vrijednosti se zatim po kanalima oduzimaju svim podacima -- podacima za treniranje, podacima za validaciju i podacima za testiranje.

Kako su sve arhitekture korištene za potrebe ovog rada izgrađene na naučenom prednjem dijelu arhitekture VGG-16, učenje se obavlja kroz 50 epoha i to na sljedeći način:
\begin{itemize}
 \item 10 epoha učenja s početnom stopom učenja iznosa $5\cdot10^{-4}$ uz optimiranje samo novo nadodanih parametara -- svi parametri naučenog prednjeg dijela arhitekture VGG-16 ne mijenjaju se tijekom ove faze
 \item 40 epoha učenja s početnom stopom učenja iznosa $1\cdot10^{-5}$ uz optimiranje kompletnog skupa parametara (uključujući i parametre naučenog prednjeg dijela arhitekture VGG-16)
 \item korak učenja koristi gradijente izračunate nad mini-grupama veličina 5 ili 10, ovisno o memorijskoj zahtjevnosti modela
 \item za optimizaciju je korišteno učenje postupkom Adam
 \item stopa učenja se svakim korakom učenja eksponencijalno smanjuje:
 \begin{align}
  \eta_{t}=\eta_0 \cdot 0.96^{\cfrac{t}{k}},
 \end{align}
gdje je $t$ indeks koraka učenja, a $k$ je broj koraka učenja u jednoj epohi
 \item svi novo nadodani slobodni parametri (isključujući parametre prednaučenog prednjeg dijela arhitekture VGG-16) inicijalizirani su na sljedeći način:
 \begin{itemize}
  \item parametri slojeva (isključujući parametre pomaka) s po dijelovima linearnom aktivacijskom funkcijom inicijalizirani su koristeći inicijalizator koji skalira varijancu prema \citep{article:delving_deep_into_rectifiers}
  \item parametri slojeva (isključujući parametre pomaka) s normalizirajućom eksponencijalnom aktivacijskom funkcijom inicijalizirani su koristeći Xavier inicijalizaciju prema \citep{article:delving_deep_into_rectifiers}
  \item parametri pomaka svih slojeva inicijalizirani su s vrijednostima 0
 \end{itemize}

 \item slobodni parametri regularizirani su L2 normom parametara s faktorom regularizacije iznosa $5\cdot10^{-4}$
 \item podskup za validaciju korišten je za odabir slobodnih parametara modela
 \begin{itemize}
  \item na kraju svake epohe mjere se performanse modela na podskupu za validaciju
  \item za testiranje se odabire onaj skup parametara koji postiže najbolju performansu na podskupu za validaciju -- ovime se efektivno obavlja regularizacija (rano zaustavljanje) jer odabiremo onaj skup parametara koji najbolje generalizira
 \end{itemize}
\end{itemize}
Svi eksperimenti provedeni su na nVIDIA grafičkim karticama GTX 1070 i GTX Titan. 
Programska izvedba ostvarena je koristeći programski jezik Python i programski okvir TensorFlow \citep{framework:tensorflow}.
TensorFlow je vrlo popularan programski okvir za zadatke dubokog učenja jer pruža mogućnost automatske diferencijacije što omogućuje vrlo brzu izgradnju modela i provođenje eksperimenata.

Zadatak ovog rada definiran je kao binarna klasifikacija pa možemo iskoristiti 4 definirana tipa predikcija modela: 
\begin{itemize}
 \item TP \engl{true positive} -- slika koja je označena kao pozitivna (atribut pripajanja je prisutan) i za koju je predikcija modela također takva 
 \item TN \engl{true negative} -- slika koja je označena kao negativna (atribut pripajanja nije prisutan) i za koju je predikcija modela također takva
 \item FP \engl{false positive} -- slika koja je označena kao negativna, a predikcija modela je pozitivna
 \item FN \engl{false negative} -- slika koja je označena kao pozitivna, a predikcija modela je negativna
\end{itemize}
Mjere koje su uzimane u obzir prilikom evaluacije jesu točnost \engl{accuracy}, preciznost \engl{precision} i odziv \engl{recall}. 
Točnost jest definirana na sljedeći način:
\begin{align}
 \text{točnost} = \cfrac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}
\end{align}
Odziv jest definirana na sljedeći način:
\begin{align}
 \text{odziv} = \cfrac{\text{TP}}{\text{TP} + \text{FN}}
\end{align}
Preciznost jest definirana na sljedeći način:
\begin{align}
 \text{preciznost} = \cfrac{\text{TP}}{\text{TP} + \text{FP}}
\end{align}

Kako je izlaz modela vjerojatnost da je atribut pripajanja prisutan na slici, odnosno da atribut pripajanja nije prisutan na slici, definira se prag kao iznos vjerojatnosti iznad koje se smatra da je atribut prisutan.
Za različite pragove dobivaju se različite vrijednosti preciznosti i odziva modela prilikom evaluacije. 
Ucrtavanjem svih točaka koje povezuju vrijednost preciznosti i odziva za različite pragove dobivamo graf ovisnosti preciznosti i odziva.
Prosječna preciznost jest definirana kao površina ispod tog grafa.
Kako je ranije spomenuto, za izračun ostalih mjera potrebno je definirati prag iznad kojeg se smatra da je atribut pripajanja prisutan.
Vrijednost praga pronalazi se pomoću podskupa za validaciju -- izračunava se točnost na podskupu za validaciju za različite vrijednosti pragova i uzima se onaj prag kojim se dobiva najveća točnost.

\section{Klasifikacija slika s diskriminativnim oznakama na različitim rezolucijama}
Eksperimenti na slikama s diskriminativnim oznakama provedeni su koristeći arhitekturu za klasifikaciju pojedinačnih slika. 
Kako su eksperimenti nad sekvencama slika memorijski mnogo zahtjevniji od eksperimenata nad pojedinačnim slikama, svrha ovog eksperimenta bila je utvrditi
na kojoj rezoluciji ulaznih slika model gubi ekspresivnu moć i ne uspijeva dati zadovoljavajuću performansu.

Za početnu, originalnu rezoluciju pojedinačnih slika odabrana je rezolucija $700$x$280$. Eksperiment je proveden redom na sljedećim rezolucijama:
$700$x$280$, $525$x$210$, $350$x$140$ i $175$x$70$. Rezultati su dani u nastavku.

\subsection{Rezultati na rezoluciji 700x280}
Konačni rezultati dobiveni za eksperiment s ulaznim podacima rezolucije $700$x$280$ su sljedeći:

\begin{table}[H]
\centering
\caption{Rezultati na rezoluciji $700$x$280$ bez pretprocesiranja}
\label{score:single_hand_700x280_no_preprocess}
\begin{tabular}{c|c|c|c|c|}
\cline{2-5}
                                            & točnost & preciznost & odziv & prosječna preciznost \\ \hline
\multicolumn{1}{|c|}{podskup za učenje}     & 0.99       & 0.98        & 1.0     &           0.99           \\ \hline
\multicolumn{1}{|c|}{podskup za validaciju} & 0.96       & 0.96        & 0.95     &            0.98          \\ \hline
\multicolumn{1}{|c|}{podskup za testiranje} & 0.94       & 0.91        & 0.98     &            0.98          \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Rezultati na rezoluciji $700$x$280$}
\label{score:single_hand_700x280}
\begin{tabular}{c|c|c|c|c|}
\cline{2-5}
                                            & točnost & preciznost & odziv & prosječna preciznost \\ \hline
\multicolumn{1}{|c|}{podskup za učenje}     & 0.99       & 0.99        & 1.0     &           1.0           \\ \hline
\multicolumn{1}{|c|}{podskup za validaciju} & 0.96       & 0.93        & 0.99     &            0.99          \\ \hline
\multicolumn{1}{|c|}{podskup za testiranje} & 0.93       & 0.88        & 1.0     &            0.99          \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Odnos predikcija modela i stvarnih oznaka na rezoluciji $700$x$280$}
\label{score:single_hand_700x280_tpfptnfn}
\begin{tabular}{ccccllll}
\multicolumn{1}{l}{}                                         &                                                                      & \multicolumn{2}{c}{}                                & \multicolumn{2}{c}{}                        & \multicolumn{2}{c}{}                        \\ \hhline{~---}
\multicolumn{1}{l|}{}                                        & \multicolumn{1}{c|}{\diagbox{stvarna oznaka}{predikcija modela}} & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{1}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{-===}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za učenje}}     & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{886} & \multicolumn{1}{c|}{12}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{898} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za validaciju}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{290} & \multicolumn{1}{c|}{23}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{4}  & \multicolumn{1}{c|}{309} &                      &                      &                      &                      \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za testiranje}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{255} & \multicolumn{1}{c|}{42}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{1}  & \multicolumn{1}{c|}{296} &                      &                      &                      &                      \\ \hhline{----}
\end{tabular}
\end{table}

\noindent Tablica \ref{score:single_hand_700x280_no_preprocess} prikazuje rezultate dobivene evaluacijom modela koji je postigao najbolju performansu na podskupu za validaciju prilikom učenja na podacima koji nisu pretprocesirani.
Tablica \ref{score:single_hand_700x280} prikazuje rezultate dobivene evaluacijom modela koji je postigao najbolju performansu na podskupu za validaciju prilikom učenja.
Usporedbom tablica \ref{score:single_hand_700x280_no_preprocess} i \ref{score:single_hand_700x280} vidljivo je kako se nešto bolji rezultati dobivaju korištenjem podataka koji su pretprocesirani.
Tablica \ref{score:single_hand_700x280_tpfptnfn} prikazuje odnos predikcija modela i stvarnih oznaka kroz matrice zabune.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/single_hand_scale1_loss.png}
\caption{Kretanje prosječnog gubitka na podskupu za učenje i validaciju po epohama}
\label{img:single_hand_scale1_loss}
\end{figure}
\noindent Na slici \ref{img:single_hand_scale1_loss} vidljivo je kretanje prosječnog gubitka po epohama na podskupu za učenje i na podskupu za validaciju.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/single_hand_scale1_acc_ap.png}
\caption{Kretanje točnosti, preciznosti i odziva na podskupu za validaciju po epohama}
\label{img:single_hand_scale1_acc_ap}
\end{figure}
\noindent Na slici \ref{img:single_hand_scale1_acc_ap} vidljivo je kretanje točnosti, preciznosti i odziva po epohama na podskupu za validaciju.

\subsection{Rezultati na rezoluciji 525x210}
Konačni rezultati dobiveni za eksperiment s ulaznim podacima rezolucije $525$x$210$ su sljedeći:
\begin{table}[H]
\centering
\caption{Rezultati na rezoluciji $525$x$210$}
\label{score:single_hand_525x210}
\begin{tabular}{c|c|c|c|c|}
\cline{2-5}
                                            & točnost & preciznost & odziv & prosječna preciznost \\ \hline
\multicolumn{1}{|c|}{podskup za učenje}     & 1.0       & 1.0        & 1.0     &           1.0           \\ \hline
\multicolumn{1}{|c|}{podskup za validaciju} & 0.97       & 0.97        & 0.97     &            0.99          \\ \hline
\multicolumn{1}{|c|}{podskup za testiranje} & 0.98       & 0.97        & 0.99     &            1.0          \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Odnos predikcija modela i stvarnih oznaka na rezoluciji $525$x$210$}
\label{score:single_hand_525x210_tpfptnfn}
\begin{tabular}{ccccllll}
\multicolumn{1}{l}{}                                         &                                                                      & \multicolumn{2}{c}{}                                & \multicolumn{2}{c}{}                        & \multicolumn{2}{c}{}                        \\ \hhline{~---}
\multicolumn{1}{l|}{}                                        & \multicolumn{1}{c|}{\diagbox{stvarna oznaka}{predikcija modela}} & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{1}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{-===}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za učenje}}     & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{898} & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{898} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za validaciju}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{305} & \multicolumn{1}{c|}{8}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{10}  & \multicolumn{1}{c|}{303} &                      &                      &                      &                      \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za testiranje}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{287} & \multicolumn{1}{c|}{10}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{3}  & \multicolumn{1}{c|}{294} &                      &                      &                      &                      \\ \hhline{----}
\end{tabular}
\end{table}

\noindent Tablica \ref{score:single_hand_525x210} prikazuje rezultate dobivene evaluacijom modela koji je postigao najbolju performansu na podskupu za validaciju prilikom učenja.
Tablica \ref{score:single_hand_525x210_tpfptnfn} prikazuje odnos predikcija modela i stvarnih oznaka kroz matrice zabune.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/single_hand_scale075_loss.png}
\caption{Kretanje prosječnog gubitka na podskupu za učenje i validaciju po epohama}
\label{img:single_hand_scale075_loss}
\end{figure}
\noindent Na slici \ref{img:single_hand_scale075_loss} vidljivo je kretanje prosječnog gubitka po epohama na podskupu za učenje i na podskupu za validaciju.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/single_hand_scale075_acc_ap.png}
\caption{Kretanje točnosti, preciznosti i odziva po epohama}
\label{img:single_hand_scale075_acc_ap}
\end{figure}
\noindent Na slici \ref{img:single_hand_scale075_acc_ap} vidljivo je kretanje točnosti, preciznosti i odziva po epohama na podskupu za validaciju.

\subsection{Rezultati na rezoluciji 350x140}
Konačni rezultati dobiveni za eksperiment s ulaznim podacima rezolucije $350$x$140$ su sljedeći:

\begin{table}[H]
\centering
\caption{Rezultati na rezoluciji $350$x$140$}
\label{score:single_hand_350x140}
\begin{tabular}{c|c|c|c|c|}
\cline{2-5}
                                            & točnost & preciznost & odziv & prosječna preciznost \\ \hline
\multicolumn{1}{|c|}{podskup za učenje}     & 1.0       & 1.0        & 1.0     &           1.0           \\ \hline
\multicolumn{1}{|c|}{podskup za validaciju} & 0.95       & 0.93        & 0.97     &            0.99          \\ \hline
\multicolumn{1}{|c|}{podskup za testiranje} & 0.98       & 0.96        & 0.99     &            0.99          \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Odnos predikcija modela i stvarnih oznaka na rezoluciji $350$x$140$}
\label{score:single_hand_350x140_tpfptnfn}
\begin{tabular}{ccccllll}
\multicolumn{1}{l}{}                                         &                                                                      & \multicolumn{2}{c}{}                                & \multicolumn{2}{c}{}                        & \multicolumn{2}{c}{}                        \\ \hhline{~---}
\multicolumn{1}{l|}{}                                        & \multicolumn{1}{c|}{\diagbox{stvarna oznaka}{predikcija modela}} & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{1}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{-===}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za učenje}}     & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{898} & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{898} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za validaciju}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{291} & \multicolumn{1}{c|}{22}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{8}  & \multicolumn{1}{c|}{305} &                      &                      &                      &                      \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za testiranje}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{284} & \multicolumn{1}{c|}{13}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{1}  & \multicolumn{1}{c|}{296} &                      &                      &                      &                      \\ \hhline{----}
\end{tabular}
\end{table}

\noindent Tablica \ref{score:single_hand_350x140} prikazuje rezultate dobivene evaluacijom modela koji je postigao najbolju performansu na podskupu za validaciju prilikom učenja.
Tablica \ref{score:single_hand_350x140_tpfptnfn} prikazuje odnos predikcija modela i stvarnih oznaka kroz matrice zabune.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/single_hand_scale050_loss.png}
\caption{Kretanje prosječnog gubitka na podskupu za učenje i validaciju po epohama}
\label{img:single_hand_scale050_loss}
\end{figure}
\noindent Na slici \ref{img:single_hand_scale050_loss} vidljivo je kretanje prosječnog gubitka po epohama na podskupu za učenje i na podskupu za validaciju.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/single_hand_scale050_acc_ap.png}
\caption{Kretanje točnosti, preciznosti i odziva na podskupu za validaciju po epohama}
\label{img:single_hand_scale050_acc_ap}
\end{figure}
\noindent Na slici \ref{img:single_hand_scale050_acc_ap} vidljivo je kretanje točnosti, preciznosti i odziva po epohama na podskupu za validaciju.

\subsection{Rezultati na rezoluciji 175x70}
Konačni rezultati dobiveni za eksperiment s ulaznim podacima rezolucije $175$x$70$ su sljedeći:
\begin{table}[H]
\centering
\caption{Rezultati na rezoluciji $175$x$70$}
\label{score:single_hand_175x70}
\begin{tabular}{c|c|c|c|c|}
\cline{2-5}
                                            & točnost & preciznost & odziv & prosječna preciznost \\ \hline
\multicolumn{1}{|c|}{podskup za učenje}     & 0.99       & 0.99        & 1.0     &           1.0           \\ \hline
\multicolumn{1}{|c|}{podskup za validaciju} & 0.89       & 0.90        & 0.88     &            0.96          \\ \hline
\multicolumn{1}{|c|}{podskup za testiranje} & 0.87       & 0.84        & 0.90     &            0.92          \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Odnos predikcija modela i stvarnih oznaka na rezoluciji $175$x$70$}
\label{score:single_hand_175x70_tpfptnfn}
\begin{tabular}{ccccllll}
\multicolumn{1}{l}{}                                         &                                                                      & \multicolumn{2}{c}{}                                & \multicolumn{2}{c}{}                        & \multicolumn{2}{c}{}                        \\ \hhline{~---}
\multicolumn{1}{l|}{}                                        & \multicolumn{1}{c|}{\diagbox{stvarna oznaka}{predikcija modela}} & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{1}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{-===}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za učenje}}     & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{897} & \multicolumn{1}{c|}{1}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{898} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za validaciju}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{282} & \multicolumn{1}{c|}{31}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{39}  & \multicolumn{1}{c|}{274} &                      &                      &                      &                      \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za testiranje}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{247} & \multicolumn{1}{c|}{50}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{29}  & \multicolumn{1}{c|}{268} &                      &                      &                      &                      \\ \hhline{----}
\end{tabular}
\end{table}

\noindent Tablica \ref{score:single_hand_175x70} prikazuje rezultate dobivene evaluacijom modela koji je postigao najbolju performansu na podskupu za validaciju prilikom učenja.
Tablica \ref{score:single_hand_175x70_tpfptnfn} prikazuje odnos predikcija modela i stvarnih oznaka kroz matrice zabune.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/single_hand_scale025_loss.png}
\caption{Kretanje prosječnog gubitka na skupu za učenje i validaciju po epohama}
\label{img:single_hand_scale025_loss}
\end{figure}
\noindent Na slici \ref{img:single_hand_scale025_loss} vidljivo je kretanje prosječnog gubitka po epohama na podskupu za učenje i na podskupu za validaciju.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/single_hand_scale025_acc_ap.png}
\caption{Kretanje točnosti, preciznosti i odziva po epohama}
\label{img:single_hand_scale025_acc_ap}
\end{figure}
\noindent Na slici \ref{img:single_hand_scale025_acc_ap} vidljivo je kretanje točnosti, preciznosti i odziva po epohama na podskupu za validaciju.

\subsection{Analiza rezultata}
Svrha niza eksperimenata na slikama s diskriminativnim oznakama bila je utvrditi najnižu rezoluciju na kojoj je performansa zadovoljavajuća.
Rezolucija ulaznih slika bitan je faktor za daljnje eksperimente, jer je učenje mnogo brže na slikama niže rezolucije, i moguće je koristiti veće mini grupe za učenje.
Odabir rezolucije ulaznih slika također je bitan faktor zbog toga što će učenje na sekvencama slika biti memorijski mnogo zahtjevnije.
\begin{table}[H]
\centering
\caption{Rezultati na podskupu za testiranje}
\label{score:single_hand_test_resolutions}
\begin{tabular}{|c|c|c|c|c|}
\hline
rezolucija slika & točnost & preciznost & odziv & prosječna preciznost \\ \hline
700x280          &     0.93    &   0.88         &   1.0    &       0.99               \\ \hline
525x210          &    0.98     &    0.97        &   0.99    &       1.0               \\ \hline
350x140          &     0.98    &    0.96        &   0.99    &        0.99              \\ \hline
175x70           &    0.87     &    0.84        &   0.90    &      0.92                \\ \hline
\end{tabular}
\end{table}
Tablica \ref{score:single_hand_test_resolutions} prikazuje performanse modela na podskupu za testiranje s ulaznim slikama različitih rezolucija.
Rezulati pokazuju kako je najniža rezolucija na kojoj su performanse modela i dalje visoke, ona od $350$x$140$. 
Eksperimenti koji koriste sekvence slika iz tog će razloga koristiti ulazne slike na toj rezoluciji.

Pad performansi na rezoluciji $175$x$70$ može se objasniti time što je prednji dio arhitekture VGG-16 koji
služi za izlučivanje značajki originalno naučen na slikama rezolucije $224$x$224$. 
Zbog manje rezolucije slika, model ne uspijeva uvijek prepoznati diskriminativni dio na temelju kojeg bi donio odluku je li slika pozitivan ili negativan primjer.

\begin{figure}[H]
\centering
\includegraphics[scale=0.55]{images/pr_350_140.png}
\caption{Graf ovisnosti preciznosti i odziva}
\label{img:pr_350_140}
\end{figure}
Slika \ref{img:pr_350_140} prikazuje graf ovisnosti preciznosti i odziva na podskupu za testiranje za model koji koristi ulazne slike rezolucije $350$x$140$.

Pogreške modela na podskupu za testiranje su vrlo slične te su u nastavku prikazani tipovi pogrešaka.
Model koji radi s ulaznim podacima rezolucije $175$x$70$ izuzet je iz analize pogrešaka jer je eksperimentima pokazano da na toj rezoluciji performanse znatno padaju zbog nedovoljno informacija na temelju kojih bi model donio ispravne odluke.

\subsubsection{Lažni pozitivi \engl{false positives}}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/single_false_positive1.png}
\caption{Lažni pozitiv s diskriminativnim uzorkom (slika preuzeta s \citep{url:ftts_irap})}
\label{img:single_false_positive1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/single_false_positive2.png}
\caption{Lažni pozitiv s krajnjom lijevom trakom različite boje (slika preuzeta s \citep{url:ftts_irap})}
\label{img:single_false_positive2}
\end{figure}
Slika \ref{img:single_false_positive1} prikazuje sliku na kojoj se pojavljuje uzorak vrlo sličan uzorku prema kojem su označene pozitivne slike te je to vjerojatan uzrok krive klasifikacije.
Riječ je o slici koja je označena kao negativ jer se karakteristični uzorak pojavljuje na razdvajanju trakova, a na pozitivnim slikama se uzorak pojavljuje na pripajanju.
Slika \ref{img:single_false_positive2} prikazuje sliku na kojoj se krajnje lijevi trak bojom i strukturom razlikuje od preostalih trakova. 
Razlika krajnjeg lijevog traka moguće je utjecala na odluku modela.
Preostali lažni pozitivi su uglavnom slični navedenima.

\subsubsection{Lažni negativi \engl{false negatives}}
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/single_false_negative.png}
\caption{Lažni negativ s uzdignutim pripajanjem (slika preuzeta s \citep{url:ftts_irap})}
\label{img:single_false_negative}
\end{figure}
Slika \ref{img:single_false_negative} prikazuje sliku koju su svi modeli klasificirali kao negativnu.
Razlog moguće krive klasifikacije jest što je cesta koja se priključuje slijeva uzdignuta te karakteristični diskriminativni uzorak nije raspoređen kao na ostalim pozitivnim slikama.


\section{Klasifikacija pojedinačnih slika s oznakama iz sustava FTTS iRAP}
Za razliku od prethodnih eksperimenata, ovaj eksperiment je proveden na skupu podataka s oznakama iz sustava FTTS iRAP.
Eksperiment je proveden na pojedinačnim slikama rezolucije $700$x$280$ kako bi se u daljnjim eksperimentima moglo usporediti poboljšava li se rezultat uvođenjem dodatnih informacija sa sekvencom slika koje prethode slici za koju je određena oznaka prisutnosti atributa pripajanja.

\begin{table}[H]
\centering
\caption{Rezultati}
\label{score:single_irap}
\begin{tabular}{c|c|c|c|c|}
\cline{2-5}
                                            & točnost & preciznost & odziv & prosječna preciznost \\ \hline
\multicolumn{1}{|c|}{podskup za učenje}     & 0.95       & 0.94        & 0.96     &           0.99           \\ \hline
\multicolumn{1}{|c|}{podskup za validaciju} & 0.88       & 0.92        & 0.83     &            0.93          \\ \hline
\multicolumn{1}{|c|}{podskup za testiranje} & 0.83       & 0.87        & 0.77     &            0.91          \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Odnos predikcija modela i stvarnih oznaka}
\label{score:single_irap_tpfptnfn}
\begin{tabular}{ccccllll}
\multicolumn{1}{l}{}                                         &                                                                      & \multicolumn{2}{c}{}                                & \multicolumn{2}{c}{}                        & \multicolumn{2}{c}{}                        \\ \hhline{~---}
\multicolumn{1}{l|}{}                                        & \multicolumn{1}{c|}{\diagbox{stvarna oznaka}{predikcija modela}} & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{1}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{-===}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za učenje}}     & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{3552} & \multicolumn{1}{c|}{225}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{146}   & \multicolumn{1}{c|}{3631} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za validaciju}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{797} & \multicolumn{1}{c|}{63}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{146}  & \multicolumn{1}{c|}{714} &                      &                      &                      &                      \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za testiranje}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{728} & \multicolumn{1}{c|}{93}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{187}  & \multicolumn{1}{c|}{634} &                      &                      &                      &                      \\ \hhline{----}
\end{tabular}
\end{table}

\noindent Tablica \ref{score:single_irap} prikazuje rezultate dobivene evaluacijom modela koji je postigao najbolju performansu na podskupu za validaciju prilikom učenja.
Tablica \ref{score:single_irap_tpfptnfn} prikazuje odnos predikcija modela i stvarnih oznaka kroz matrice zabune.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/single_irap_loss.png}
\caption{Kretanje prosječnog gubitka na skupu za učenje i validaciju po epohama}
\label{img:single_irap_loss}
\end{figure}
\noindent Na slici \ref{img:single_irap_loss} vidljivo je kretanje prosječnog gubitka po epohama na podskupu za učenje i na podskupu za validaciju.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/single_irap_ac_ap.png}
\caption{Kretanje točnosti, preciznosti i odziva po epohama}
\label{img:single_irap_ac_ap}
\end{figure}
\noindent Na slici \ref{img:single_irap_ac_ap} vidljivo je kretanje točnosti, preciznosti i odziva po epohama na podskupu za validaciju.

\section{Klasifikacija sekvenci slika s oznakama iz sustava FTTS iRAP koristeći vremensko-prostorno sažimanje}
Konačni rezultati dobiveni za eksperiment sa sekvencom slika rezolucije $350$x$140$ su sljedeći:
\begin{table}[H]
\centering
\caption{Rezultati}
\label{score:pooling}
\begin{tabular}{c|c|c|c|c|}
\cline{2-5}
                                            & točnost & preciznost & odziv & prosječna preciznost \\ \hline
\multicolumn{1}{|c|}{podskup za učenje}     & 0.91       & 0.96        & 0.85     &           0.97           \\ \hline
\multicolumn{1}{|c|}{podskup za validaciju} & 0.89       & 0.96        & 0.82     &            0.95          \\ \hline
\multicolumn{1}{|c|}{podskup za testiranje} & 0.80       & 0.93        & 0.65     &            0.91          \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Odnos predikcija modela i stvarnih oznaka}
\label{score:pooling_tptnfpfn}
\begin{tabular}{ccccllll}
\multicolumn{1}{l}{}                                         &                                                                      & \multicolumn{2}{c}{}                                & \multicolumn{2}{c}{}                        & \multicolumn{2}{c}{}                        \\ \hhline{~---}
\multicolumn{1}{l|}{}                                        & \multicolumn{1}{c|}{\diagbox{stvarna oznaka}{predikcija modela}} & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{1}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{-===}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za učenje}}     & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{3650} & \multicolumn{1}{c|}{127}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{572}   & \multicolumn{1}{c|}{3205} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za validaciju}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{830} & \multicolumn{1}{c|}{30}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{155}  & \multicolumn{1}{c|}{705} &                      &                      &                      &                      \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za testiranje}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{782} & \multicolumn{1}{c|}{39}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{288}  & \multicolumn{1}{c|}{533} &                      &                      &                      &                      \\ \hhline{----}
\end{tabular}
\end{table}

\noindent Tablica \ref{score:pooling} prikazuje rezultate dobivene evaluacijom modela koji je postigao najbolju performansu na podskupu za validaciju prilikom učenja.
Tablica \ref{score:pooling_tptnfpfn} prikazuje odnos predikcija modela i stvarnih oznaka kroz matrice zabune.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/pooling_loss.png}
\caption{Kretanje prosječnog gubitka na skupu za učenje i validaciju po epohama}
\label{img:pooling_loss}
\end{figure}
\noindent Na slici \ref{img:pooling_loss} vidljivo je kretanje prosječnog gubitka po epohama na podskupu za učenje i na podskupu za validaciju.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/pooling_ac_ap.png}
\caption{Kretanje točnosti, preciznosti i odziva po epohama}
\label{img:pooling_ac_ap}
\end{figure}
\noindent Na slici \ref{img:pooling_ac_ap} vidljivo je kretanje točnosti, preciznosti i odziva po epohama na podskupu za validaciju.

\section{Klasifikacija sekvenci slika s oznakama iz sustava FTTS iRAP koristeći povratne LSTM ćelije}
Konačni rezultati dobiveni za eksperiment sa sekvencijalnim ulaznim podacima rezolucije $350$x$140$ su sljedeći:

\begin{table}[H]
\centering
\caption{Rezultati}
\label{score:lstm}
\begin{tabular}{c|c|c|c|c|}
\cline{2-5}
                                            & točnost & preciznost & odziv & prosječna preciznost \\ \hline
\multicolumn{1}{|c|}{podskup za učenje}     & 0.98       & 0.98        & 0.99     &           0.99           \\ \hline
\multicolumn{1}{|c|}{podskup za validaciju} & 0.90       & 0.94        & 0.85     &            0.94          \\ \hline
\multicolumn{1}{|c|}{podskup za testiranje} & 0.86       & 0.88        & 0.82     &            0.93          \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Odnos predikcija modela i stvarnih oznaka}
\label{score:lstm_tptnfpfn}
\begin{tabular}{ccccllll}
\multicolumn{1}{l}{}                                         &                                                                      & \multicolumn{2}{c}{}                                & \multicolumn{2}{c}{}                        & \multicolumn{2}{c}{}                        \\ \hhline{~---}
\multicolumn{1}{l|}{}                                        & \multicolumn{1}{c|}{\diagbox{stvarna oznaka}{predikcija modela}} & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{1}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{-===}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za učenje}}     & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{3681} & \multicolumn{1}{c|}{96}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{21}   & \multicolumn{1}{c|}{3756} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za validaciju}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{812} & \multicolumn{1}{c|}{48}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{131}  & \multicolumn{1}{c|}{729} &                      &                      &                      &                      \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za testiranje}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{733} & \multicolumn{1}{c|}{88}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{149}  & \multicolumn{1}{c|}{672} &                      &                      &                      &                      \\ \hhline{----}
\end{tabular}
\end{table}

\noindent Tablica \ref{score:lstm} prikazuje rezultate dobivene evaluacijom modela koji je postigao najbolju performansu na podskupu za validaciju prilikom učenja.
Tablica \ref{score:lstm_tptnfpfn} prikazuje odnos predikcija modela i stvarnih oznaka kroz matrice zabune.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/lstm_loss.png}
\caption{Kretanje prosječnog gubitka na skupu za učenje i validaciju po epohama}
\label{img:lstm_loss}
\end{figure}
\noindent Na slici \ref{img:lstm_loss} vidljivo je kretanje prosječnog gubitka po epohama na podskupu za učenje i na podskupu za validaciju.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/lstm_ac_ap.png}
\caption{Kretanje točnosti, preciznosti i odziva po epohama}
\label{img:lstm_ac_ap}
\end{figure}
\noindent Na slici \ref{img:lstm_ac_ap} vidljivo je kretanje točnosti, preciznosti i odziva po epohama na podskupu za validaciju.

\section{Klasifikacija sekvenci slika s oznakama iz sustava FTTS iRAP koristeći vremenski potpuno povezani sloj}
Konačni rezultati dobiveni za eksperiment sa sekvencijalnim ulaznim podacima rezolucije $350$x$140$ su sljedeći:

\begin{table}[H]
\centering
\caption{Rezultati}
\label{score:temporal}
\begin{tabular}{c|c|c|c|c|}
\cline{2-5}
                                            & točnost & preciznost & odziv & prosječna preciznost \\ \hline
\multicolumn{1}{|c|}{podskup za učenje}     & 0.99       & 0.99        & 1.0     &           1.0           \\ \hline
\multicolumn{1}{|c|}{podskup za validaciju} & 0.89       & 0.99        & 0.79     &            0.96          \\ \hline
\multicolumn{1}{|c|}{podskup za testiranje} & 0.86       & 0.96        & 0.74     &            0.94          \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\caption{Odnos predikcija modela i stvarnih oznaka}
\label{score:temporal_tptnfpfn}
\begin{tabular}{ccccllll}
\multicolumn{1}{l}{}                                         &                                                                      & \multicolumn{2}{c}{}                                & \multicolumn{2}{c}{}                        & \multicolumn{2}{c}{}                        \\ \hhline{~---}
\multicolumn{1}{l|}{}                                        & \multicolumn{1}{c|}{\diagbox{stvarna oznaka}{predikcija modela}} & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{1}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{-===}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za učenje}}     & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{3775} & \multicolumn{1}{c|}{2}   & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{0}   & \multicolumn{1}{c|}{3777} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} & \multicolumn{1}{c}{} \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za validaciju}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{850} & \multicolumn{1}{c|}{10}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{181}  & \multicolumn{1}{c|}{679} &                      &                      &                      &                      \\ \hhline{====}
\multicolumn{1}{|c|}{\multirow{2}{*}{podskup za testiranje}} & \multicolumn{1}{c|}{0}                                               & \multicolumn{1}{c|}{794} & \multicolumn{1}{c|}{27}   &                      &                      &                      &                      \\ \hhline{~---}
\multicolumn{1}{|c|}{}                                       & \multicolumn{1}{c|}{1}                                               & \multicolumn{1}{c|}{211}  & \multicolumn{1}{c|}{610} &                      &                      &                      &                      \\ \hhline{----}
\end{tabular}
\end{table}

\noindent Tablica \ref{score:temporal} prikazuje rezultate dobivene evaluacijom modela koji je postigao najbolju performansu na podskupu za validaciju prilikom učenja.
Tablica \ref{score:temporal_tptnfpfn} prikazuje odnos predikcija modela i stvarnih oznaka kroz matrice zabune.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/temporal_loss.png}
\caption{Kretanje prosječnog gubitka na skupu za učenje i validaciju po epohama}
\label{img:temporal_loss}
\end{figure}
\noindent Na slici \ref{img:temporal_loss} vidljivo je kretanje prosječnog gubitka po epohama na podskupu za učenje i na podskupu za validaciju.

\begin{figure}[H]
\centering
\includegraphics[scale=0.35]{images/temporal_ac_ap.png}
\caption{Kretanje točnosti, preciznosti i odziva po epohama}
\label{img:temporal_ac_ap}
\end{figure}
\noindent Na slici \ref{img:temporal_ac_ap} vidljivo je kretanje točnosti, preciznosti i odziva po epohama na podskupu za validaciju.

\section{Analiza rezultata}
Svrha niza eksperimenata provedenih na slikama s oznakama iz sustava FTTS iRAP jest ustanoviti performansu sustava na oznakama dodijeljenima od strane eksperata, prema naputcima organizacije iRAP.
Provedeni su eksperimenti na pojedinačnim slikama i na sekvencama slika kako bi se ustanovilo dobiva li se na performansama uvođenjem dodatnih informacija kroz sekvencu slika koja prethodi označenoj slici.

\subsection{Analiza rezultata na slikama s oznakama iz sustava FTTS iRAP}
Prvi dio eksperimenata na podacima s oznakama iz sustava FTTS iRAP proveden je nad pojedinačnim slikama. 
Vidljiv je značajniji pad performansi u odnosu na slike s diskriminativnim oznakama. 
Razlog tomu jest način na koji su slike u sustavu FTTS iRAP označene, kako je objašnjeno u poglavlju \ref{chapter:skupovi_podataka}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.55]{images/single_irap_false_positive.png}
\caption{Lažni pozitiv (slika preuzeta s \citep{url:ftts_irap})}
\label{img:single_irap_false_positive}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.55]{images/single_irap_false_negative.png}
\caption{Lažni negativ (slika preuzeta s \citep{url:ftts_irap})}
\label{img:single_irap_false_negative}
\end{figure}

Slike \ref{img:single_irap_false_positive} i \ref{img:single_irap_false_negative} prikazuju po jedan primjer lažnog negativa i lažnog pozitiva iz podskupa za testiranje.
Težina zadatka očituje se ukoliko promotrimo koliko su obe slike slične.
Sustavu za detekciju atributa iz tog je razloga potrebno više informacija od onih koje uspije izlučiti iz pojedine slike.
Zbog toga je korištena sekvenca slika koja prethodi pojedinim slikama označenima kao pozitivnima.

\subsection{Analiza rezultata na sekvencama slika s oznakama iz sustava FTTS iRAP}
Kako su eksperimenti pokazali, uvođenjem sekvence slika koja prethodi označenoj slici dobiva se na performansama u odnosu na pojedinačne slike s oznakama iz sustava FTTS iRAP. 
Najbolji rezultati dobiveni su modelom koji dobivene prostorne značajke obrađuje koristeći vremenski potpuno povezani sloj.

Performanse modela koji prostorne značajke slika s oznakama iz sustava FTTS iRAP obrađuje vremenskim potpuno povezanim slojem i dalje su niže od performansi modela za pojedinačne slike na slikama s diskriminativnim oznakama.
Pad performansi možemo analizirati tako da promotrimo slike iz podskupa za testiranje koje model loše klasificira. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.55]{images/pr_temporal.png}
\caption{Graf ovisnosti preciznosti i odziva}
\label{img:pr_temporal}
\end{figure}
Slika \ref{img:pr_temporal} prikazuje graf ovisnosti preciznosti i odziva na podskupu za testiranje.

U nastavku su pokazani najčešći tipovi pogrešaka modela.

\subsubsection{Lažni pozitivi \engl{false positives}}
\begin{figure}[H]
\centering
\includegraphics[scale=1]{images/fp_1.png}
\caption{Lažni pozitiv s lijevom trakom različite boje (slika preuzeta s \citep{url:ftts_irap})}
\label{img:fp_1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=1]{images/fp_2.png}
\caption{Lažni pozitiv s diskriminativnim uzorcima kakvi se pojavljuju kod pripajanja (slika preuzeta s \citep{url:ftts_irap})}
\label{img:fp_2}
\end{figure}

Slika \ref{img:fp_1} prikazuje cestu gdje je lijeva traka različite boje od ostalih. 
Model mnogo takvih sličnih primjera označava kao pozitivne. Moguć razlog je što ga različitost lijeve trake može podsjećati na pripajanje.
Slika \ref{img:fp_2} prikazuje razdvajanje koje ima vrlo slične diskriminativne uzorke onima na pripajanjima. 
Modelu je iz tog razloga teško donijeti odluku je li riječ o pozitivu ili negativu.

\subsubsection{Lažni negativi \engl{false negatives}}
\begin{figure}[H]
\centering
\includegraphics[scale=1]{images/fn_1.png}
\caption{Lažni negativ s razdvajanjem službeno označenim kao pripajanje (slika preuzeta s \citep{url:ftts_irap})}
\label{img:fn_1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=1]{images/fn_2.png}
\caption{Lažni negativ s pripajanjem na suprotnoj strani autoceste službeno označenim kao pripajanje (slika preuzeta s \citep{url:ftts_irap})}
\label{img:fn_2}
\end{figure}

Slika \ref{img:fn_1} prikazuje situaciju u kojoj je razdvajanje, prema službenim oznakama sustava FTTS iRAP, označeno kao pripajanje. 
Slika \ref{img:fn_2} prikazuje situaciju u kojoj se dogodilo da je zbog prisutnosti pripajanja na drugoj strani autoceste i promatrana sekvenca u sustavu označena kao pozitivna.

\section{Detekcije krivih oznaka}
Analizom lažnih pozitiva i lažnih negativa sa skupa za testiranje utvrđeno je kako se lažni negativi pojavljuju u sekvencama -- kompletni dijelovi video snimaka označeni atributom pripajanja trakova su klasificirani pogrešno.
Lažni pozitivi uglavnom se pojavljuju pojedinačno, bez slijedova lažno klasificiranih pozitivnih slika.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{images/wrong_lane_label.png}
\caption{Oznaka atributa pripajanja dodijeljena drugom traku (slika preuzeta s \citep{url:google_maps})}
\label{img:wrong_lane_label}
\end{figure}

U razgovoru s kreatorima sustava FTTS iRAP zaključeno je kako je moguće da postoje moguće nekonzistentnosti i krive oznake atributa pripajanja uslijed ljudske pogreške i uslijed načina na koji se oznake dodjeljuju.
Analizom geolokacija slika koje su pogrešno klasificirane utvrđeno je kako uglavnom dolazi do sljedeće situacije: atributi pripajanja su po geolokaciji pridruženi drugom traku što je prikazano na slici \ref{img:wrong_lane_label}.
Vidljivo je kako je pripajanje ustvari na drugom traku od originalne geolokacije atributa pripajanja. 

Iz tog razloga skup podataka sadrži ``nečistoće'' koje je potrebno validirati sa samim sustavom. 
Podatak koji se u tom slučaju može pokazati kao koristan, osim geolokacije svakog primjera iz skupa podataka, i podatak o tome događaju li se iste klasifikacijske pogreške kod različitih modela.
Analizom je utvrđeno da modeli uglavnom griješe na istim primjerima -- pokazuje se da su na preko 50\% primjera iz skupa za testiranje pogriješila sva 3 modela za klasifikaciju sekvenci slika.
Na taj način moguće je relativno brzo provjeriti sve sumnjive primjere iz skupa podataka, eventualno im promijeniti oznaku prisutnosti atributa pripajanja te generirati novi, nekontaminirani skup podataka.

\chapter{Zaključak}
Organizacija iRAP bavi se inspekcijom kvaliteta ceste pridruživanjem različitih sigurnosnih atributa segmentima prometnica. 
Sustav FTTS iRAP je geolokacijski informacijski sustav koji sadrži video snimke s geolokacijskim oznakama i pridruženim sigurnosnim atributima prema naputcima organizacije iRAP. 
Označavanje segmenata video snimaka obavlja se ručno što može biti skupo, vremenski zahtjevno i otvara mogućnost za brojne pogreške. 

Duboko učenje donijelo je revoluciju u području računalnog vida. 
Cilj rada bio je iskoristiti moć dubokog učenja i pokušati napraviti sustav zasnovan na dubokom modelu koji bi iz video snimaka naučio automatski označavati jedan od velikog broja sigurnosnih atributa - pripajanje trakova na autocesti.
Pripajanje trakova na autocesti je vrlo rizično zbog mogućnosti da dođe do prometne nesreće.
Prednost korištenja dubokog modela jest jeftinije i objektivnije pridruživanje sigurnosnih atributa segmentima video snimaka. 
Konačno naučen sustav postizao je zadovoljavajuću performanse s obzirom na nekonzistentnost oznaka skupa podataka. 
Naučen sustav može se iskoristiti za brzu validaciju ručno označenih atributa. 
Svaki uzorak koji model krivo označi potencijalno je pogrešno označen i u sustavu pa je iz njegove geolokacije moguće brzo validirati prisutnost atributa pripajanja.

Prvi korak za budući rad i poboljšanje sustava bio bi odrediti sve krive oznake u sustavu FTTS iRAP, generirati novi skup podataka s pročišćenim oznakama te ponovno naučiti model na nekontaminiranim podacima.
Nadalje, pokazano je kako korištenje sekvenci slika dovodi do povećanja performansi modela -- poboljšanje bi se moglo ostvariti korištenjem mnogo duljih sekvenci uz rjeđe uzorkovanje te uz uzorkovanje slika koje prethode i koje slijede pojedinačnoj slici od interesa. 
Moguća poboljšanja mogla bi se ostvariti i u vidu korištenja modernijih naučenih arhitektura korištenih za tipične zadatke u računalnom vidu.

\bibliography{literatura}
\bibliographystyle{fer}

\begin{sazetak}
Ovaj rad opisuje modeliranje i učenje dubokih modela za klasifikaciju sekvenci prometnih scena.
Svrha učenje takvih modela jest automatizirati dodjeljivanje sigurnosnih atributa definiranih od strane organizacije iRAP.
Dodjeljivanje sigurnosnih atributa u različitim sustavima trenutno se obavlja ručno.
Korištenje dubokih modela pruža jeftiniju i objektivniju alternativu takvom zadatku.

Predloženo je nekoliko arhitektura koje rade s pojedinačnim slikama i sa sekvencama slika te koje je moguće učiti s kraja na kraj.
Skupovi podataka generirani su na dva načina. Prvi skup podataka generiran je označavanjem slika na kojima diskriminativni uzorak prisutan.
Drugi skup podataka generiran je automatiziranom metodom preuzimanja slika označenih atributom ``pripajanje trakova'' u sustavu FTTS iRAP.
Prikazani su eksperimentalni rezultati dobiveni nad oba skupa.
Skup podataka s diskriminativnim oznakama korišten je za pronalaženje najniže rezolucije na kojoj se ručno označene pojedinačne slike i dalje klasificiraju uspješno. 
Pronalazak niske rezolucije slika na kojoj klasifikacija i dalje uspješno radi važna je zbog toga što je na nižim rezolucijama učenje brže i moguće je koristiti veće mini grupe.
Niska rezolucija slika je također važna jer je učenje nad sekvencama slika memorijski zahtjevnije od učenja na pojedinačnim slikama.
Skup podataka označen na temelju podataka iz sustava FTTS iRAP korišten je za usporedbu dobitka na performansama uvođenjem dodatnih informacija kroz sekvencu slika.
Pokazali smo da sustav može pomoći pri detekciji krivo označenih atributa.


\kljucnerijeci{duboko učenje, sekvencijalni podaci, iRAP sigurnosni atributi, klasifikacija, prometne scene} \\
\end{sazetak}

\newpage
% TODO: Navedite naslov na engleskom jeziku.
\engtitle{Detection of road-assessment attributes in video}
\begin{abstract}
This paper describes modeling and training of deep models for classification of traffic scene sequences.
Purpose of training the model for classifications of traffic scenes is to automate the assignment of safety attributes defined by the iRAP organization.
Assignment of safety attributes in different systems is being performed manually at the moment.
Usage of the deep models provides cheaper and more objective alternative for that task.

Several architectures that work with single images and image sequences and which can be trained end-to-end are suggested.
Datasets are generated in two ways.
First dataset is generated by labeling images with discriminative pattern present on image.
Second dataset is generated by automated method for downloading images labeled with ``merge lane'' attribute in FTTS iRAP system.
Experimental results on both datasets are presented.
Dataset with discriminative labels is used to find the lowest resolution on which manually labeled single images are still successfully classified.
Determining low image resolution on which classification still works successfully is important because training on lower resolutions is faster and it is possible to use larger mini batches.
Low image resolution is also important because training on image sequences has greater memory requirements than training on single images.
Dataset with labels based on the data from FTTS iRAP system is used to compare performance gain with introducing the additional information through the image sequences.
We showed that system can help with detection of wrongly labeled attributes.

\keywords{deep learning, sequence data, iRAP safety attributes, classification, traffic scenes}
\end{abstract}

\end{document}
